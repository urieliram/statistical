{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOI3YRq0qbg1V4FpL2PNKS+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urieliram/statistical/blob/main/Tarea11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl8U_TJwYnCt",
        "outputId": "26499a76-8ed2-4a85-87c7-27d807452c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split #--------------splitting data into test and train\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from IPython.core.pylabtools import figsize\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline\n",
        "!sudo pip3 install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D\n",
        "from tensorflow.keras.layers import LocallyConnected2D\n",
        "from tensorflow.keras.layers import LocallyConnected1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "print(tf.__version__)\n",
        "from matplotlib import pyplot as plt\n",
        "from random import randint\n",
        "\n",
        "import keras\n",
        "from   keras.models import Sequential\n",
        "from   keras.layers import Dense"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03KT7DFyii20",
        "outputId": "e51fd840-da9a-47ea-eb27-546012bbe282"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predicción de sobrecarga en grupos de líneas de transmisión.\n",
        "En esta sección se usará inferencia bayesiana para ajustar un modelo de regresión logística a datos de violación de flujo de potencia eléctrica en grupos de líneas de transmisión, que interconectan regiones eléctricas. La variable dependientes es de naturaleza binaria con un valor de uno si la línea presenta sobrecarga y cero si no. Las variables independientes son el flujo neto máximo y mínimo en la región eléctrica en un día y se calcula como la diferencia entre la demanda menos la generación en cada región."
      ],
      "metadata": {
        "id": "Oq5QAPZbZFIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('overload.csv')\n",
        "df = df.assign(const=1)\n",
        "dfy = df[['L3','L5','L6','L7','L14','L15','L22','L31','L38','L39','L51','L58','L65']] #Se escoge le número de línea de transmisión\n",
        "dfx = df[['CEN','NES','NOR','NTE','OCC','ORI','PEN','CEN_min','NES_min','NOR_min','NTE_min','OCC_min','ORI_min','PEN_min']] ## Predictors\n",
        "\n",
        "X = dfx.to_numpy()\n",
        "y = dfy.to_numpy()\n",
        "\n",
        "#Normalizing the data\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "y = ohe.fit_transform(y).toarray()\n",
        "\n",
        "## Crea conjuntos de datos de entrenamiento y prueba\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.7) #, random_state = 5\n",
        "\n",
        "#df.sample(5)\n",
        "#df.describe()\n",
        "# df.head()"
      ],
      "metadata": {
        "id": "YHm2TKzKJj1L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación se enlista las configuraciones de red usadas en el libro (para resolver el problema *11.7 Example: ZIP Code Data*). \n",
        "*   Net-1: Sin capa oculta, equivalente a regresión logística multinomial.\n",
        "*   Net-2: Una capa oculta, 12 unidades ocultas totalmente conectadas.\n",
        "*   Net-3: Dos capas ocultas conectadas localmente.\n",
        "*   Net-4: Dos capas ocultas, conectadas localmente con peso compartido.\n",
        "*   Net-5: dos capas ocultas, conectadas localmente, dos niveles de peso compartido.\n",
        "\n",
        "Trataremos de replicar el ejercicio aplicando a nuestros datos. A diferencia del problema de 2dimensiones del libro , usaremos redes para una sola dimensión para predecir un vector de Binarios (Sobrecarga o no de algunas líneas de tranmisión) a partir de un vector de datos reales (datos de demanda de las regiones eléctricas). También mencionan que todas las redes tienen unidades de salida sigmoidales y el ajuste es con mínimpos cuadrados.\n"
      ],
      "metadata": {
        "id": "fyP3Pfx9i0bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://towardsdatascience.com/building-our-first-neural-network-in-keras-bdc8abbc17f5\n",
        "## Neural network\n",
        "\n",
        "num_classes = 26 ## {salidas}\n",
        "\n",
        "model = Sequential()\n",
        "input_dim = 14\n",
        "\n",
        "## Net-1\n",
        "#model.add(Dense(units = num_classes, input_dim = 14, activation='sigmoid' )) ## FUNCIONA !!! , activation='relu',\n",
        "\n",
        "## Net-2\n",
        "#model.add(Dense(units=12, input_dim = input_dim,  activation ='sigmoid' ))\n",
        "#model.add(Dense(units=num_classes,         activation ='sigmoid'))\n",
        "\n",
        "'''\n",
        "## Net-3\n",
        "input_dim = (14,1)\n",
        "#input_ = Input(input_dim, name = 'the_input')\n",
        "#layer1 = LocallyConnected1D(1, 2, strides= 2, activation= 'sigmoid', name = 'layer1')(input_)\n",
        "#layer2 = LocallyConnected1D(1, 5, activation='sigmoid', name = 'layer2')(layer1)\n",
        "#layer3 = Flatten(name='layer3')(layer2) \n",
        "#output = Dense(units=num_classes, activation='sigmoid', name = 'output')(layer3)\n",
        "\n",
        "#model = Model(inputs = input_, outputs = output)\n",
        "#input_dim = np.expand_dims(input_dim, axis=0)\n",
        "'''\n",
        "'''\n",
        "## Net-4\n",
        "input_dim = (14,1)\n",
        "input_ = Input(input_dim, name = 'the_input')\n",
        "layer1 = Conv1D(filters=2, kernel_size=2, strides=2, activation='sigmoid', name='layer1')(input_) \n",
        "layer2 = LocallyConnected1D(1, 5, activation='sigmoid', name='layer2')(layer1)\n",
        "layer3 = Flatten(name='layer3')(layer2) \n",
        "output = Dense(units=num_classes, activation='sigmoid', name = 'output')(layer3)\n",
        "\n",
        "model = Model(inputs = input_, outputs = output)\n",
        "input_dim = np.expand_dims(input_dim, axis=0)\n",
        "'''\n",
        "\n",
        "'''\n",
        "## Net-5\n",
        "input_dim = (14,1)\n",
        "input_ = Input(input_dim, name = 'the_input')\n",
        "layer1 = Conv1D(2, 2, strides= 2, activation= 'sigmoid', name = 'layer1')(input_)\n",
        "layer2 = Conv1D(4, 5, activation='sigmoid', name = 'layer2')(layer1)\n",
        "layer3 = Flatten(name='layer3')(layer2) \n",
        "output = Dense(units=num_classes, activation='sigmoid', name = 'output')(layer3)\n",
        "\n",
        "model = Model(inputs = input_, outputs = output)\n",
        "input_dim = np.expand_dims(input_dim, axis=0)\n",
        "'''\n",
        "\n",
        "## LeNet\n",
        "Hg = 200\n",
        "Lng = 80\n",
        "\n",
        "#Layer 1\n",
        "#Conv Layer 1\n",
        "input_dim = (14,1)\n",
        "model.add(Conv1D(filters = 6, kernel_size = 5, strides = 1, activation = 'relu', \n",
        "                 input_shape = input_dim ))\n",
        "#Pooling layer 1\n",
        "model.add(MaxPooling1D(pool_size = 2, strides = 2))\n",
        "#Layer 2\n",
        "#Conv Layer 2\n",
        "model.add(Conv1D(filters = 16, kernel_size = 5,strides = 1,activation = 'relu',\n",
        "                 input_shape = input_dim ))\n",
        "#Pooling Layer 2\n",
        "model.add(MaxPooling1D(pool_size = 2, strides = 2))\n",
        "\n",
        "#Flatten\n",
        "model.add(Flatten())\n",
        "#Layer 3\n",
        "#Fully connected layer 1\n",
        "model.add(Dense(units = 120, activation = 'relu'))\n",
        "#Layer 4\n",
        "#Fully connected layer 2\n",
        "model.add(Dense(units = 84, activation = 'relu'))\n",
        "#Layer 5\n",
        "#Output Layer\n",
        "model.add(Dense(units = 2, activation = 'sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "fxGqkvDWi9_G",
        "outputId": "136ba7ba-bc86-4b99-a024-0823d1c136ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-06247e9a07be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m                  input_shape = input_dim ))\n\u001b[1;32m     69\u001b[0m \u001b[0;31m#Pooling Layer 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;31m#Flatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   6064\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6065\u001b[0m     x = tf.compat.v1.nn.max_pool(\n\u001b[0;32m-> 6066\u001b[0;31m         x, pool_size, strides, padding=padding, data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   6067\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6068\u001b[0m     x = tf.compat.v1.nn.avg_pool(\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling1d_1\" (type MaxPooling1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling1d_1/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 1, 1], padding=\"VALID\", strides=[1, 2, 1, 1]](max_pooling1d_1/ExpandDims)' with input shapes: [?,1,1,16].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 1, 16), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametros https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) #RMSprop, categorical_crossentropy, adam, binary_crossentropy, categorical_crossentropy"
      ],
      "metadata": {
        "id": "wogbeqm9i_J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs     = 100 \n",
        "batch_size = 64\n",
        "verbose    = 0\n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose) "
      ],
      "metadata": {
        "id": "k54yEdixjce5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "#Converting predictions to label\n",
        "pred = list()\n",
        "for i in range(len(y_pred)):\n",
        "    pred.append(np.argmax(y_pred[i]))\n",
        "#Converting one hot encoded test label to label\n",
        "test = list()\n",
        "for i in range(len(y_test)):\n",
        "    test.append(np.argmax(y_test[i]))"
      ],
      "metadata": {
        "id": "q3zvsxo524i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = accuracy_score(pred,test)\n",
        "print('Accuracy is:', a*100)"
      ],
      "metadata": {
        "id": "vuRTB9O7lZZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, validation_data = (X_test,y_test), epochs=epochs, batch_size=batch_size,verbose=verbose) #epochs =200 batch_size =64"
      ],
      "metadata": {
        "id": "hwjiHFFl2A0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Exactitud del modelo')\n",
        "plt.ylabel('Exactitud')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Entrenamiento', 'Prueba'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lDFCTPTnihaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss']) \n",
        "plt.plot(history.history['val_loss']) \n",
        "plt.title('Pérdida en el modelo') \n",
        "plt.ylabel('Pérdida') \n",
        "plt.xlabel('Epoch') \n",
        "plt.legend(['Entrenamiento', 'Prueba'], loc='upper left') \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Ry6imDvinsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conclusión:** \n",
        "Hemos utilizado la API funcional de **Keras** para implementar diferentes estructuras de redes neuronales para predicción de sobrecarga en líneas de transmisión de acuerdo a la demanda en las regiones.\n",
        "\n",
        "Los resultadosindica que la mejor estructura es........... sin embargo, el ............ algunas ventajas ya que da la posibilidad de ................, mientrass.\n",
        "\n",
        "Otra cosa que observamos es que .............., los rendimientos de predicción son similares. Esto quiere decir que a medida que crece el conjunto de datos los resultados deberían converger en la misma solución."
      ],
      "metadata": {
        "id": "Ql3ADEdWZY3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Ejemplos KERAS](https://keras.io/examples/)\n",
        "\n",
        "[Model class API](https://faroit.com/keras-docs/1.2.2/models/model/)\n",
        "\n",
        "[The Functional API TUTORIAL](https://keras.io/guides/functional_api/)\n",
        "\n",
        "[https://gist.github.com/jkleint/1d878d0401b28b281eb75016ed29f2ee](https://gist.github.com/jkleint/1d878d0401b28b281eb75016ed29f2ee)\n",
        "\n",
        "[Introduction to 1D Convolutional Neural Networks in Keras for Time Sequences](https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf)\n",
        "\n",
        "[1D Convolutional Neural Network Models for Human Activity Recognition](https://machinelearningmastery.com/cnn-models-for-human-activity-recognition-time-series-classification/)"
      ],
      "metadata": {
        "id": "gyYCVhnKqHRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://stackoverflow.com/questions/49161174/tensorflow-logits-and-labels-must-have-the-same-first-dimension\n",
        "\n",
        "#n_class = 2\n",
        "#n_features = 14\n",
        "#inputs = keras.Input(shape=(n_features,))\n",
        "\n",
        "#inputs.shape\n",
        "#inputs.dtype\n",
        "\n",
        "#dense = layers.Dense(14, activation = \"sigmoid\")\n",
        "#x = dense(inputs)\n",
        "\n",
        "#x = layers.Dense(14, activation=\"sigmoid\")(x)\n",
        "#outputs = layers.Dense(14)(x)\n",
        "\n",
        "#outputs = x\n",
        "\n",
        "#model = keras.Model(inputs=inputs, outputs=outputs, name = \"overload_model\")\n",
        "\n",
        "#np.expand_dims(inputs,axis=0)\n",
        "\n",
        "#model.summary()\n",
        "\n",
        "#keras.utils.plot_model(model, \"fig_t11_1.png\")\n",
        "#keras.utils.plot_model(model, \"fig_t11_2.png\", show_shapes=True)"
      ],
      "metadata": {
        "id": "z_MhV61PZEg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.models import Model\n",
        "#from keras.layers import Input, Dense\n",
        "\n",
        "#a = Input(shape=(32,))\n",
        "#b = Dense(32)(a)\n",
        "#model = Model(Input=a, Output=b)\n",
        "#compile(self, optimizer, loss, metrics=None, loss_weights=None, sample_weight_mode=None)\n",
        "#fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0)"
      ],
      "metadata": {
        "id": "mFgH6kNqc5ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.compile(\n",
        "#    loss      = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "#    optimizer = keras.optimizers.RMSprop(),\n",
        "#    metrics=[\"accuracy\"],\n",
        "#)\n",
        "\n",
        "#history = model.fit(x_train, y_train, batch_size=14, epochs=2, validation_split=0.2)\n",
        "\n",
        "#test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "#print(\"Test loss:\", test_scores[0])\n",
        "#print(\"Test accuracy:\", test_scores[1])"
      ],
      "metadata": {
        "id": "p45sI-QcSo0M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}