{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea15.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM4wr62W9qdx6QX2e674OAI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urieliram/statistical/blob/main/Tarea15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JboE4Y4YndQq"
      },
      "outputs": [],
      "source": [
        "pip install dtw-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
        "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV, LarsCV\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_absolute_percentage_error\n",
        "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
        "from math import sqrt\n",
        "from dtw import *\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "DuC_OkW4nm78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trunc(values, decs=0):\n",
        "    return np.trunc(values*10**decs)/(10**decs)"
      ],
      "metadata": {
        "id": "EcNqmPCJP_yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CYAN = '#76ced6' ; LILA = '#777bd4'; VERDE='#17cb49'; NARA='#ff8000'; AZUL='#168fff'; OTROAZUL = \"b-\"; ROJO= \"r-\";\n",
        "def print_serie2(serie_,prototipo_,title_,ytitle_,xtitle_,sizex_=7,sizey_=4,namefile_='figure.png'):\n",
        "    fig, ax1 = plt.subplots(figsize=(sizex_,sizey_))\n",
        "    plt.title(title_,fontsize='x-large',color=NARA)\n",
        "    ax1.set_xlabel(xtitle_, color=NARA, fontsize='large')\n",
        "    ax1.set_ylabel(ytitle_, color=NARA, fontsize='large')\n",
        "    plt.tick_params(colors = NARA, which='both')\n",
        "    ax1.spines['bottom'].set_color(NARA)\n",
        "    ax1.spines['top'   ].set_color(NARA) \n",
        "    ax1.spines['right' ].set_color(NARA)\n",
        "    ax1.spines['left'  ].set_color(NARA)\n",
        "    if len(prototipo_) != 0: \n",
        "        plt.plot(prototipo_,alpha=0.6, linestyle='dashed', color='red', linewidth=3)\n",
        "    for p in serie_:\n",
        "        plt.plot(p,alpha=0.3, linewidth=2)    \n",
        "    plt.savefig(namefile_, transparent=True)         \n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9cnF4RJ6no8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Preparamos la información para graficar la importancia y las posiciones en Random Forest Regressor\n",
        "def print_importances(model_,labels_):\n",
        "    i=0\n",
        "    labels = [str(x) for x in labels_]\n",
        "    labels_importances = []\n",
        "    for feature in model_.feature_importances_:\n",
        "        labels_importances.append((feature,labels[i]))\n",
        "        i=i+1   \n",
        "    labels_importances.sort(key=lambda tup: tup[0], reverse=False)\n",
        "    importances = []\n",
        "    labels      = []\n",
        "    for tup in labels_importances:\n",
        "        importances.append(tup[0])\n",
        "        labels.append(tup[1])\n",
        "    fig, ax = plt.subplots()\n",
        "    y_pos = np.arange(len(importances))\n",
        "    ax.set_yticks(ticks=y_pos)\n",
        "    ax.barh(labels, importances, align='center')\n",
        "    ax.invert_yaxis()\n",
        "    ax.set_xlabel('Importancia')\n",
        "    ax.set_ylabel('Variable')\n",
        "    ax.set_title( 'Importancia de las variables del bosque aleatorio')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ofhg0JCdoR-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Encuentra los vecinos más cercanos\n",
        "def get_neighbors(train, test_row, num_neighbors, typedist='euclidean'):\n",
        "  \n",
        "    distances = list()\n",
        "\n",
        "    for train_row in train:\n",
        "        if typedist == 'dtw':\n",
        "            dist = dtw(test_row, train_row)\n",
        "        else:\n",
        "            dist = euclidean(test_row, train_row)\n",
        "        distances.append((train_row, dist))\n",
        "    distances.sort(key=lambda tup: tup[1])\n",
        "\n",
        "    neighbors = list()\n",
        "\n",
        "    for i in range(num_neighbors):\n",
        "        neighbors.append(distances[i][0])\n",
        "    return neighbors\n",
        "\n",
        "## Calcula distancia euclidiana\n",
        "def euclidean(neig1, neig2):\n",
        "\t  distance = 0.0\n",
        "\t  for i in range(len(neig1)):\n",
        "\t\t    distance += (neig1[i] - neig2[i])**2\n",
        "\t  return sqrt(distance)"
      ],
      "metadata": {
        "id": "qW1nbNEyns85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://drive.google.com/drive/folders/1Gj3XK9kM-lE18uBMe3qrZOGEm8yAI8i9\n",
        "#https://www.codegrepper.com/code-examples/python/how+to+read+csv+file+from+google+drive+on+google+colab+\n",
        "path        = 'https://drive.google.com/uc?export=download&id=' \n",
        "URL_Demanda = 'https://drive.google.com/file/d/1xcpXDTE7H6EBMLOkic5lq-lzSwiLG2ZS/view?usp=sharing'\n",
        "df_Demanda  = pd.read_csv(path + URL_Demanda .split('/')[-2], usecols=[0] ) #names=['CLVUNI','TYPE','NODE'], usecols=[1,2,3,4,5,6,], 1,2,3,4,5,6,7,8,9,10,11,12,13,15,\n",
        "df_Demanda.dropna(inplace=True)\n",
        "serie = df_Demanda.to_numpy()\n",
        "serie = StandardScaler().fit_transform(serie)\n",
        "serie = serie.ravel() ## Con esto quitamos el bracket o corchete en cada uno de loselementos del arreglo"
      ],
      "metadata": {
        "id": "7RW90yl-nu87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analogo_knn(serie,vsel,vreg,k=10,tol=0.8,typedist='euclidian',typereg='OLS'):    \n",
        "#    vsel       : tamanio de la ventana de selección\n",
        "#    vreg       : tamanio de la ventana de regresión\n",
        "#    k       : número de vecinos a buscar k\n",
        "#    tol     : tolerancia de tamaño de ventanas para seleccion de vecinos\n",
        "#    typedist: medida de distancia, 'dtw' o 'euclidian' o 'pearson'\n",
        "\n",
        "    t_o = time.time()\n",
        "    n = len(serie) ## longitud total de la serie\n",
        "\n",
        "    ## PASO 1: Selección de las ventanas de mayor correlación.\n",
        "\n",
        "    ## Calculamos la distancia entre todos los vecinos.\n",
        "    v = vsel\n",
        "    distances = []\n",
        "    Y = serie[n-v:n]           ## últimos datos\n",
        "    for i in range(n-2*v):\n",
        "        if  typedist == 'dtw': ## dynamic time warping\n",
        "            dist = dtw(Y, serie[i:i+v]).distance  \n",
        "        elif typedist == 'pearson':\n",
        "            dist = np.corrcoef(Y,serie[i:i+v])[1,0]\n",
        "        else:\n",
        "            dist = euclidean(Y,serie[i:i+v])\n",
        "        if dist > 0:\n",
        "            distances.append((i, dist))\n",
        "        \n",
        "    ## Calculamos el vecindario por distancia de menor a mayor y se guardan las posiciones.\n",
        "    if typedist == 'pearson':\n",
        "        ## En caso de pearson se ordena al revés, nos interesan los mayor correlación.\n",
        "        distances.sort(key=lambda tup: tup[1], reverse=True)\n",
        "    else:\n",
        "        ## En caso de pearson se ordena al revés, nos interesan los de menor distancia.\n",
        "        distances.sort(key=lambda tup: tup[1], reverse=False)\n",
        "\n",
        "    neighbors  = []\n",
        "    neighbors2 = []\n",
        "    positions  = []\n",
        "\n",
        "    ## Calculamos los k vecinos mas cercanos y guardamos las posiciones.\n",
        "    i = 0\n",
        "    for pos, dis in distances:\n",
        "        if i==0:      \n",
        "            positions.append(pos)   \n",
        "            neighbors.append(serie[pos:pos+v])\n",
        "            neighbors2.append(serie[pos+v:pos+2*v])\n",
        "        else:\n",
        "            bandera = True\n",
        "            for p in positions:\n",
        "                 ## si ya teniamos una posición en la lista que pase la tolerancia, ya no guardamos \n",
        "                if (abs(pos - p) < tol*v):\n",
        "                    bandera = False\n",
        "                    i = i - 1\n",
        "                    break\n",
        "            if bandera == True:\n",
        "                ## Guarda nuevo vecino\n",
        "                positions.append(pos)   \n",
        "                neighbors.append(serie[pos:pos+v])\n",
        "                neighbors2.append(serie[pos+v:pos+2*v])\n",
        "                bandera = False\n",
        "        i = i + 1\n",
        "        if i == k:\n",
        "            break\n",
        "    #print('positions KNN:',positions) ## posición de los k vecinos mas cercanos\n",
        "\n",
        "    neighbors  = np.array(neighbors)  \n",
        "    neighbors2 = np.array(neighbors2)    \n",
        "    vacia = []\n",
        "    print_serie2(neighbors,Y, 'KNN - (X) - ' + typedist,'demanda','time',7,4,'fig_1')\n",
        "    #print_serie2(neighbors2,vacia, 'KNN - X2 (prima)','demanda','time',7,4,'fig_2')\n",
        "\n",
        "    t_sel = time.time() - t_o\n",
        "\n",
        "    ## PASO 2: Regresión entre los vecinos mas cercanos 'X' y la última ventana 'Y'\n",
        "\n",
        "    ## Definimos nuestros regresores   \n",
        "    X   = (neighbors.T).tolist()\n",
        "    X_2 = (neighbors2.T).tolist()\n",
        "    Y   = (Y).tolist()\n",
        "    prediction_Y2 = []\n",
        "\n",
        "    ## Regresión -- OLS with Stepwise --\n",
        "    if typereg == 'OLS':\n",
        "        model   = sm.OLS(Y, X)\n",
        "        results = model.fit()\n",
        "        prediction_Y2 = results.predict(X_2)\n",
        "\n",
        "        ## Ordenamos los valores 'pi' y se selecciona el más grande.\n",
        "        i = 0\n",
        "        pvalues = []\n",
        "        for pi in results.pvalues:\n",
        "            pvalues.append((i,pi))\n",
        "            i = i + 1\n",
        "        pvalues.sort(key=lambda tup: tup[1], reverse=True) ## Ordenamos por 'pi'\n",
        "        (i, pi) = pvalues[0]  \n",
        "\n",
        "        while pi > 0.001:\n",
        "            X   = sm.add_constant(X)\n",
        "            X_2 = sm.add_constant(X_2) \n",
        "            print('Retiramos regresor ---> X' + str(i))\n",
        "            X   = np.delete(arr=X,   obj=i+0, axis=1)\n",
        "            X_2 = np.delete(arr=X_2, obj=i+0, axis=1)   \n",
        "            model   = sm.OLS(Y, X)\n",
        "            results = model.fit()\n",
        "\n",
        "            ## Ordenamos los valores 'pi' y se selecciona el más grande\n",
        "            i = 0\n",
        "            pvalues = []\n",
        "            for pi in results.pvalues:\n",
        "                pvalues.append((i,pi))\n",
        "                i = i + 1\n",
        "            pvalues.sort(key=lambda tup: tup[1], reverse=True) ## Ordenamos por 'pi'\n",
        "            (i, pi) = pvalues[0]\n",
        "            #prediction   = results.predict(X)   ## Ajuste\n",
        "            prediction_Y2 = results.predict(X_2) ## Pronóstico\n",
        "        if len(prediction_Y2) == 0:\n",
        "            print('>>> Warning, no variable was significant in the regression.')\n",
        "            model   = sm.OLS(Y, X)\n",
        "            results = model.fit()\n",
        "            prediction_Y2 = results.predict(X_2)\n",
        "\n",
        "        print(results.summary())\n",
        "\n",
        "    ## Voting regression \n",
        "    ## https://scikit-learn.org/stable/auto_examples/ensemble/plot_voting_regressor.html#sphx-glr-auto-examples-ensemble-plot-voting-regressor-py\n",
        "    if typereg == 'Voting':\n",
        "        reg1 = GradientBoostingRegressor(random_state=1)\n",
        "        reg2 = RandomForestRegressor(random_state=1)\n",
        "        reg3 = LinearRegression()\n",
        "        reg1.fit(X, Y)\n",
        "        reg2.fit(X, Y)\n",
        "        reg3.fit(X, Y)\n",
        "        ereg = VotingRegressor([(\"gb\", reg1), (\"rf\", reg2), (\"lr\", reg3)])\n",
        "        ereg.fit(X, Y)\n",
        "        prediction_Y2 = ereg.predict(X_2)\n",
        "\n",
        "    ## Regresión -- Random Forrest Regression 100 --\n",
        "    if typereg == 'RF':\n",
        "        model         = RandomForestRegressor(n_estimators=100,random_state=42,) ##default\n",
        "        results       = model.fit(X, Y)\n",
        "        prediction_Y2 = results.predict(X_2)\n",
        "        print_importances(model_=model,labels_=positions)\n",
        "\n",
        "    ## Regresión -- Random Forrest Regression with GridSearchCV--\n",
        "    ## https://www.kaggle.com/code/sociopath00/random-forest-using-gridsearchcv/notebook\n",
        "    if typereg == 'AutoRF':\n",
        "\n",
        "        nestlist = []\n",
        "        for i in range(0, 300, 50):\n",
        "            nestlist.append(i)\n",
        "        param_grid = { \n",
        "        'n_estimators': nestlist,\n",
        "        'max_features': ['auto', 'sqrt', 'log2'],\n",
        "        'max_depth' : [4,5,6,7,8],\n",
        "        'criterion' :['gini', 'entropy']}\n",
        "\n",
        "        model = RandomForestRegressor(random_state=42)\n",
        "        clf   = GridSearchCV(estimator=model, param_grid=param_grid, cv=5).fit(X, Y)\n",
        "        model         = clf.best_estimator_\n",
        "        results       = model.fit(X, Y)\n",
        "        prediction_Y2 = results.predict(X_2)\n",
        "        print_importances(model_=model,labels_=positions)\n",
        "\n",
        "        print(\"n_estimators:       {}\".format(model.n_estimators))\n",
        "        print(\"max_features:       {}\".format(model.max_features))\n",
        "        print(\"max_depth:       {}\".format(model.max_depth))\n",
        "        print(\"criterion:       {}\".format(model.criterion))\n",
        "            \n",
        "    print_serie2(neighbors2,prediction_Y2, 'Pronóstico - ' + typedist+' - ' + typereg ,'Demanda','Tiempo',7,4,'fig_2')\n",
        "\n",
        "    t_reg = time.time() - t_sel - t_o\n",
        "\n",
        "    return prediction_Y2, t_sel, t_reg"
      ],
      "metadata": {
        "id": "yz9CDOHQnx0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Parámetros de prueba.\n",
        "vsel = 2016; vreg = 2016; k = 6 ; tol = 0.8\n",
        "dias = 2\n",
        "false_end = dias * vreg ## Usa dias*v como número de dias hacia atrás para hacer pruebas de dos ventanas hacia atras\n",
        "\n",
        "## Dibujamos la ventana de histórico y los datos de prueba  \n",
        "series = []; vacia = []\n",
        "series.append(serie[len(serie)-12*false_end : len(serie)-false_end + vreg])\n",
        "series.append(serie[len(serie)-12*false_end : len(serie)-false_end ])\n",
        "print_serie2(serie_=series,prototipo_=vacia , title_='Serie de demanda eléctrica', ytitle_='Demanda (estandarizada)',xtitle_='Tiempo', sizex_=30, sizey_=7, namefile_='fig_1')"
      ],
      "metadata": {
        "id": "WapmM09KUQBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Probamos el modelo con 'pearson' y 'RF'.\n",
        "\n"
      ],
      "metadata": {
        "id": "gvk7sSA5EUD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 1==1:\n",
        "    x_train = serie[0 : len(serie) - false_end]\n",
        "    y_test  = serie[len(serie) - false_end : len(serie) - false_end + vreg]\n",
        "    pred_pea_rf, t_sel_pea_rf, t_reg_pea_rf = analogo_knn(x_train,vsel=vsel,vreg=vreg,k=k,tol=tol,typedist='pearson',typereg='RF')\n",
        "\n",
        "    # Exactitud del modelo\n",
        "    mae_pea_rf  = mean_absolute_error(y_test,pred_pea_rf)\n",
        "    mape_pea_rf = mean_absolute_percentage_error(y_test,pred_pea_rf)"
      ],
      "metadata": {
        "id": "QleIxgKXEUPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Probamos el modelo con 'pearson' y 'AutoRF'.\n",
        "\n"
      ],
      "metadata": {
        "id": "dAsqjdWXBaZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 1==1:\n",
        "    x_train = serie[0 : len(serie) - false_end]\n",
        "    y_test  = serie[len(serie) - false_end : len(serie) - false_end + vreg]\n",
        "    pred_pea_arf, t_sel_pea_arf, t_reg_pea_arf = analogo_knn(x_train,vsel=vsel,vreg=vreg,k=k,tol=tol,typedist='pearson',typereg='AutoRF')\n",
        "\n",
        "    # Exactitud del modelo\n",
        "    mae_pea_arf  = mean_absolute_error(y_test,pred_pea_arf)\n",
        "    mape_pea_arf = mean_absolute_percentage_error(y_test,pred_pea_arf)"
      ],
      "metadata": {
        "id": "bIZGvGtyBj78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Probamos el modelo con 'pearson' y 'OLS'."
      ],
      "metadata": {
        "id": "l3OmgWRtYl-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 1==1:\n",
        "    x_train = serie[0 : len(serie) - false_end]\n",
        "    y_test  = serie[len(serie) - false_end : len(serie) - false_end + vreg]\n",
        "    pred_pea_ols, t_sel_pea_ols, t_reg_pea_ols = analogo_knn(x_train,vsel=vsel,vreg=vreg,k=k,tol=tol,typedist='pearson',typereg='OLS')\n",
        "\n",
        "    # Exactitud del modelo\n",
        "    mae_pea_ols  = mean_absolute_error(y_test,pred_pea_ols)    \n",
        "    mape_pea_ols = mean_absolute_percentage_error(y_test,pred_pea_ols)"
      ],
      "metadata": {
        "id": "SEhLWFrCYldR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Probamos el modelo con 'pearson' y 'Voting'."
      ],
      "metadata": {
        "id": "lcYvprEWG5qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 1==0:\n",
        "    x_train = serie[0 : len(serie) - false_end]\n",
        "    y_test  = serie[len(serie) - false_end : len(serie) - false_end + vreg]\n",
        "    pred_pea_vot, t_sel_pea_vot, t_reg_pea_vot = analogo_knn(x_train,vsel=vsel,vreg=vreg,k=k,tol=tol,typedist='pearson',typereg='Voting')\n",
        "\n",
        "    # Exactitud del modelo\n",
        "    mae_pea_vot = mean_absolute_error(y_test,pred_pea_vot)\n",
        "    mape_pea_vot = mean_absolute_percentage_error(y_test,pred_pea_vot)"
      ],
      "metadata": {
        "id": "6ApA8i3kG5qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Probamos el modelo con 'euclidian' y 'OLS' "
      ],
      "metadata": {
        "id": "2ONaxTlmQ9gQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 1==0:\n",
        "    x_train = serie[0 : len(serie) - false_end]\n",
        "    y_test  = serie[len(serie) - false_end : len(serie) - false_end + vreg]\n",
        "    pred_euc_ols, t_sel_euc_ols, t_reg_euc_ols = analogo_knn(x_train,vsel=vsel,vreg=vreg,k=k,tol=tol,typedist='euclidian',typereg='OLS')\n",
        "\n",
        "    # Exactitud del modelo\n",
        "    mae_euc_ols  = mean_absolute_error(y_test,pred_euc_ols)\n",
        "    mape_euc_ols = mean_absolute_percentage_error(y_test,pred_euc_ols)"
      ],
      "metadata": {
        "id": "t4s_nyH9S7jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Probamos el modelo con 'euclidian' y 'RF'.\n",
        "\n"
      ],
      "metadata": {
        "id": "g9WpI4LuMr5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 1==0:\n",
        "    x_train = serie[0 : len(serie) - false_end]\n",
        "    y_test  = serie[len(serie) - false_end : len(serie) - false_end + vreg]\n",
        "    pred_euc_rf, t_sel_euc_rf, t_reg_euc_rf = analogo_knn(x_train,vsel=vsel,vreg=vreg,k=k,tol=tol,typedist='euclidian',typereg='RF')\n",
        "\n",
        "    # Exactitud del modelo\n",
        "    mae_euc_rf  = mean_absolute_error(y_test,pred_euc_rf)\n",
        "    mape_euc_rf = mean_absolute_percentage_error(y_test,pred_euc_rf)"
      ],
      "metadata": {
        "id": "ks7PMmKiM4Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Probamos el modelo con 'euclidian' y 'Voting'."
      ],
      "metadata": {
        "id": "AFsJZM3xyaqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 1==0:\n",
        "    x_train = serie[0 : len(serie) - false_end]\n",
        "    y_test  = serie[len(serie) - false_end : len(serie) - false_end + vreg]\n",
        "    pred_euc_vot, t_sel_euc_vot, t_reg_euc_vot = analogo_knn(x_train,vsel=vsel,vreg=vreg,k=k,tol=tol,typedist='euclidian',typereg='Voting')\n",
        "\n",
        "    # Exactitud del modelo\n",
        "    mae_euc_vot  = mean_absolute_error(y_test,pred_euc_vot)\n",
        "    mape_euc_vot = mean_absolute_percentage_error(y_test,pred_euc_vot)"
      ],
      "metadata": {
        "id": "-nrFb2ilya3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Probamos el modelo con 'dtw' y 'OLS'."
      ],
      "metadata": {
        "id": "jHp_MvzxPS3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 1==0:\n",
        "    x_train = serie[0 : len(serie) - false_end]\n",
        "    y_test  = serie[len(serie) - false_end : len(serie) - false_end + vreg]\n",
        "    pred_dtw_ols, t_sel_dtw_ols, t_reg_dtw_ols = analogo_knn(x_train,vsel=vsel,vreg=vreg,k=k,tol=tol,typedist='dtw',typereg='OLS')\n",
        "\n",
        "    # Exactitud del modelo\n",
        "    mae_dtw_ols  = mean_absolute_error(y_test,pred_dtw_ols)\n",
        "    mape_dtw_ols = mean_absolute_percentage_error(y_test,pred_dtw_ols)"
      ],
      "metadata": {
        "id": "EY4A5aklO9UW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Probamos el modelo con 'dtw' y 'RF'."
      ],
      "metadata": {
        "id": "Gom_i027NI6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 1==0:\n",
        "    x_train = serie[0 : len(serie) - false_end]\n",
        "    y_test  = serie[len(serie) - false_end : len(serie) - false_end + vreg]\n",
        "    pred_dtw_rf, t_sel_dtw_rf, t_reg_dtw_rf = analogo_knn(x_train,vsel=vsel,vreg=vreg,k=k,tol=tol,typedist='dtw',typereg='RF')\n",
        "\n",
        "    # Exactitud del modelo\n",
        "    mae_dtw_rf  = mean_absolute_error(y_test,pred_dtw_rf)\n",
        "    mape_dtw_rf = mean_absolute_percentage_error(y_test,pred_dtw_rf)"
      ],
      "metadata": {
        "id": "QZ8Ssf9wNH9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Comparamos graficamente los resultados\n",
        "\n"
      ],
      "metadata": {
        "id": "UUWwvdYNRGyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('| SELECCIÓN      | REGRESIÓN      | MAE             | MAPE             | TIEMPO SELECCIÓN     | TIEMPO REGRESIÓN   |')\n",
        "print('| :------------- | :------------- | -------------:  | -------------:   |-------------:        |-------------:        |')\n",
        "print('| PEARSON        | OLS + STEP     |',str(trunc(mae_pea_ols,4)),'         |',str(trunc(mape_pea_ols,4)),'         |',str(trunc(t_sel_pea_ols,4)),'              |   ',str(trunc(t_reg_pea_ols,4)),     '|')\n",
        "#print('| EUCLIDIAN      | OLS + STEP     |',str(trunc(mae_euc_ols,4)),'          |',str(trunc(mape_euc_ols,4)),'           |',str(trunc(t_sel_euc_ols,4)),'             |   ',str(trunc(t_reg_euc_ols,4)),    '|')\n",
        "#print('| DTW            | OLS + STEP     |',str(trunc(mae_dtw_ols,4)),'         |',str(trunc(mape_dtw_ols,4)),'         |',str(trunc(t_sel_dtw_ols,4)),'            |   ',str(trunc(t_reg_dtw_ols,4)),    '|')\n",
        "print('| PEARSON        | RF             |',str(trunc(mae_pea_rf,4)),'         |',str(trunc(mape_pea_rf,4)),'          |',str(trunc(t_sel_pea_rf,4)),'              |   ',str(trunc(t_reg_pea_rf,4)),    '|')\n",
        "print('| PEARSON        | AutoRF            |',str(trunc(mae_pea_arf,4)),'         |',str(trunc(mape_pea_arf,4)),'          |',str(trunc(t_sel_pea_arf,4)),'              |   ',str(trunc(t_reg_pea_arf,4)),    '|')\n",
        "#print('| EUCLIDIAN      | RF             |',str(trunc(mae_euc_rf,4)),'          |',str(trunc(mape_euc_rf,4)),'         |',str(trunc(t_sel_euc_rf,4)),'              |   ',str(trunc(t_reg_euc_rf,4)),     ' |')\n",
        "#print('| DTW            | RF             |',str(trunc(mae_dtw_rf,4)),'         |',str(trunc(mape_dtw_rf,4)),'          |',str(trunc(t_sel_dtw_rf,4)),'            |   ',str(trunc(t_reg_dtw_rf,4)),    '|')\n",
        "#print('| PEARSON        | Voting         |',str(trunc(mae_pea_vot,4)),'         |',str(trunc(mape_pea_vot,4)),'         |',str(trunc(t_sel_pea_vot,4)),'            |   ',str(trunc(t_reg_pea_vot,4)),    '|')\n",
        "#print('| EUCLIDIAN        | Voting         |',str(trunc(mae_euc_vot,4)),'         |',str(trunc(mape_euc_vot,4)),'         |',str(trunc(t_sel_euc_vot,4)),'            |   ',str(trunc(t_reg_euc_vot,4)),    '|')"
      ],
      "metadata": {
        "id": "oL_8uHE-WPwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig  = plt.figure(figsize=(35,9))\n",
        "axes = fig.add_subplot(1, 1, 1)\n",
        "axes.legend()\n",
        "CYAN = '#76ced6' ; LILA = '#777bd4'; VERDE='#17cb49'; LETRASNARA ='#ff8000'; NARA ='#ff8000'; AZUL='#168fff'; GRIS = '#808080'\n",
        "mytitle = plt.title('Pronóstico de demanda eléctrica') # get the title property handler #plt.getp(title_obj)\n",
        "plt.setp(mytitle,    color=LETRASNARA) #set the color of title to red\n",
        "axes.xaxis.label.set_color(LETRASNARA)\n",
        "axes.yaxis.label.set_color(LETRASNARA)\n",
        "axes.tick_params(colors=LETRASNARA, which='both')\n",
        "\n",
        "AUX = np.arange( len(y_test) )\n",
        "plt.scatter ( AUX, y_test, s=25,marker='o', color = 'red', label = 'Y', alpha=1/2)\n",
        "#axes.plot   ( y_test ,      '.-', color = 'red' , label = 'Y',         alpha=1/4)\n",
        "#axes.plot   ( pred_euc_ols, '.-', color = CYAN  , label = 'Y_euc_ols', alpha=1/2)\n",
        "axes.plot   ( pred_pea_ols, '.-', color = VERDE , label = 'Y_pea_ols', alpha=1/2)\n",
        "#axes.plot   ( pred_dtw_ols, '.-', color = LILA  , label = 'Y_dtw_ols', alpha=1/2)\n",
        "#axes.plot   ( pred_euc_rf, '.-',  color = NARA  , marker='x', label = 'Y_euc_rf', alpha=1/2)\n",
        "axes.plot   ( pred_pea_rf,  '.-', color = GRIS  , marker='x', label = 'Y_pea_rf' , alpha=1/2)\n",
        "axes.plot   ( pred_pea_arf,  '.-', color = AZUL  , marker='x', label = 'Y_pea_arf' , alpha=1/2)\n",
        "#axes.plot   ( pred_dtw_rf, '.-',  color = AZUL  , label = 'Y_dtw_rf', alpha=1/2)\n",
        "#axes.plot   ( pred_pea_vot, '.-', color = LILA  , label = 'Y_pea_vot', alpha=1/2)\n",
        "#axes.plot   ( pred_euc_vot, '.-', color = VERDE  , label = 'Y_euc_vot', alpha=1/2)\n",
        "#axes.plot  ( xspline[3], yspline[3] , '.-'  , color = VERDE   , label = 'orden=4'  ,alpha=1/2)\n",
        "#plt.scatter( dfx_miss, dfy_miss, marker='x',  s=170 ,  color = 'red' , label = 'perdidos' ,alpha=1)\n",
        "\n",
        "#plt.axis([0,  600, 7650, 9800])\n",
        "#plt.axis([100,  200, 7650, 9500])\n",
        "#plt.axis([400,  500, 7450, 9500])\n",
        "#plt.axis([-2,  100, 8100, 9600])\n",
        "#plt.axis([300, 400, 7900, 9500])\n",
        "\n",
        "axes.spines['bottom'].set_color(LETRASNARA)\n",
        "axes.spines['top'   ].set_color(LETRASNARA) \n",
        "axes.spines['right' ].set_color(LETRASNARA)\n",
        "axes.spines['left'  ].set_color(LETRASNARA)\n",
        "plt.legend()  \n",
        "plt.xticks(rotation=90)\n",
        "plt.savefig('fig_t15_ajuste_prono.png', transparent=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WEhE46GFn1wI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ligas interesantes\n",
        "[link texHow to Develop a Random Forest Ensemble in Python](https://machinelearningmastery.com/random-forest-ensemble-in-python/)\n",
        "\n",
        "[Random Forest using GridSearchCV](https://www.kaggle.com/code/sociopath00/random-forest-using-gridsearchcv/notebook)"
      ],
      "metadata": {
        "id": "eyRgIpSPswGc"
      }
    }
  ]
}