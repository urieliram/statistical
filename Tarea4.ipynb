{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNaj4QfWRpXzJiTTeFtLEKb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urieliram/statistical/blob/main/Tarea4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea 4\n",
        "*Pick one of the examples of the chapter that use the data of the book and replicate it in Python. Then, apply the steps in your own data.*\n",
        "\n",
        "Los datos utilizados en este cuaderno están disponibles aquí: [datasets](https://drive.google.com/drive/folders/159GnBJQDxTY9oYqPBZzdNghyb4Gd9pDS?usp=sharing) \n",
        "\n",
        "Liga de RLM en Python: [RLM](https://www.sfu.ca/~mjbrydon/tutorials/BAinPy/10_multiple_regression.html) \n"
      ],
      "metadata": {
        "id": "rNdNNQ6Bg4Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import warnings\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV, LarsCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import scipy.stats\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.tools.eval_measures as bias\n",
        "import seaborn as sns\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "9Oijys50y_S7"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión líneal con matriz indicadora en clasificación de vocales\n",
        "A continuación repetiremos el ejemplo de clasificación de vocales de la lengua inglesa del [libro](https://link.springer.com/book/10.1007/978-0-387-84858-7) en el que se aplica un modelo de regresión lineal con una matriz indicadora **(Linear Regression of an Indicator Matrix)**."
      ],
      "metadata": {
        "id": "VNF249dj3PvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iniciamos cargando los datos de entrenamiento y almacenamos en `y_train`:"
      ],
      "metadata": {
        "id": "0hheNiw834vE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Procesamos datos de entrenamiento \n",
        "df = pd.read_csv('SAheart.csv')\n",
        "dfy = df['chd']  ## Outcome\n",
        "dfx = df[['sbp','tobacco','ldl','adiposity','famhist','typea','obesity','alcohol','age']]  ## Predictors\n",
        "## Procesamos datos de prueba \n",
        "df = pd.read_csv('SAheart.csv')\n",
        "dfyt = df['chd']  ## Outcome\n",
        "dfxt = df[['sbp','tobacco','ldl','adiposity','famhist','typea','obesity','alcohol','age']]  ## Predictors"
      ],
      "metadata": {
        "id": "DE3NhzSJ3PSI"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = dfx.to_numpy()   ## Predictors\n",
        "X_train = sm.add_constant(X_train)\n",
        "y_train = dfy.to_numpy()   ## Outcome\n",
        "X_test  = dfxt.to_numpy()   ## Predictors\n",
        "X_test = sm.add_constant(X_train)\n",
        "y_test  = dfyt.to_numpy()   ## Outcome\n",
        "X_train.tofile('sample.csv',sep=',')"
      ],
      "metadata": {
        "id": "BVyOCV1VixLw"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##https://www.geeksforgeeks.org/logistic-regression-using-statsmodels/\n",
        "log_reg = sm.Logit(dfy, dfx).fit()\n",
        "print(log_reg.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xhj6XmIM_8Wq",
        "outputId": "ac9b1642-ced8-4838-f9bd-05da2c5fc051"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.536857\n",
            "         Iterations 6\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                    chd   No. Observations:                  462\n",
            "Model:                          Logit   Df Residuals:                      453\n",
            "Method:                           MLE   Df Model:                            8\n",
            "Date:                Fri, 28 Jan 2022   Pseudo R-squ.:                  0.1678\n",
            "Time:                        04:51:47   Log-Likelihood:                -248.03\n",
            "converged:                       True   LL-Null:                       -298.05\n",
            "Covariance Type:            nonrobust   LLR p-value:                 4.166e-18\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "sbp           -0.0070      0.005     -1.413      0.158      -0.017       0.003\n",
            "tobacco        0.0865      0.026      3.300      0.001       0.035       0.138\n",
            "ldl            0.1614      0.059      2.747      0.006       0.046       0.277\n",
            "adiposity      0.0671      0.028      2.434      0.015       0.013       0.121\n",
            "famhist        0.9287      0.224      4.149      0.000       0.490       1.367\n",
            "typea          0.0104      0.010      1.021      0.307      -0.010       0.030\n",
            "obesity       -0.1797      0.041     -4.410      0.000      -0.260      -0.100\n",
            "alcohol       -0.0002      0.004     -0.037      0.970      -0.009       0.009\n",
            "age            0.0271      0.011      2.496      0.013       0.006       0.048\n",
            "==============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Según el libro se aplicó una estrategia de **stepwise** en el se encuentra un subconjunto de las variables que son suficientes para explicar su efecto conjunto sobre la prevalencia de la variable *chd*. Una forma de proceder es descartar el coeficiente menos significativo y reajustar el modelo. Esto se hace repetidamente hasta que no se puedan eliminar más términos del modelo. Esto dio el modelo que se muestra en la Tabla siguiente:"
      ],
      "metadata": {
        "id": "_8jPgHMXD8tS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Rn0rQURKD8Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra manera de obtener una regresión logistica es con la librería **sklearn** tal como se muestra a continuación."
      ],
      "metadata": {
        "id": "lVNgnL1wB2D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logisticRegr = LogisticRegression()\n",
        "logisticRegr.fit(X_train, y_train)\n",
        "logisticRegr.predict(X_test[0].reshape(1,-1))\n",
        "logisticRegr.predict(X_test[0:10])\n",
        "predictions = logisticRegr.predict(X_test)\n",
        "\n",
        "error = y_test - predictions\n",
        "# Use score method to get accuracy of model\n",
        "score = logisticRegr.score(X_test, y_test)\n",
        "parametros=logisticRegr.get_params(deep=False)\n",
        "print(parametros)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aZF0sMP226n",
        "outputId": "540b5e7a-b279-4e05-c29c-0119329b4364"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
            "0.7229437229437229\n"
          ]
        }
      ]
    }
  ]
}