{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqDJF37tB0aq2Dx/M7wQ3Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urieliram/statistical/blob/main/Tarea4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea 4\n",
        "*Pick one of the examples of the chapter that use the data of the book and replicate it in Python. Then, apply the steps in your own data.*\n",
        "\n",
        "Los datos utilizados en este cuaderno están disponibles aquí: [datasets](https://drive.google.com/drive/folders/159GnBJQDxTY9oYqPBZzdNghyb4Gd9pDS?usp=sharing)"
      ],
      "metadata": {
        "id": "rNdNNQ6Bg4Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import warnings\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV, LarsCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error,confusion_matrix, accuracy_score, r2_score\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import scipy.stats\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.tools.eval_measures as bias\n",
        "import seaborn as sns\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "9Oijys50y_S7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091d53af-52c2-4657-ad93-09f0c201077c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión logística en predicción de enfermedades cardiacas\n",
        "A continuación repetiremos el ejemplo 4.4.2 de predicción de enfermedad cardiaca en Sudafrica **(South African Heart Disease)** del [libro](https://link.springer.com/book/10.1007/978-0-387-84858-7)."
      ],
      "metadata": {
        "id": "VNF249dj3PvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iniciamos cargando los datos de entrenamiento y almacenamos en `y_train`:"
      ],
      "metadata": {
        "id": "0hheNiw834vE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Procesamos datos de entrenamiento \n",
        "df = pd.read_csv('SAheart.csv')\n",
        "df=df.assign(const=1)\n",
        "print(df)\n",
        "dfy = df['chd']  ## Outcome\n",
        "dfx = df[['const','sbp','tobacco','ldl','adiposity','famhist','obesity','alcohol','age']]  ## Predictors\n",
        "\n",
        "## Procesamos datos de prueba \n",
        "dfyt = df['chd']  ## Outcome\n",
        "dfxt = df[['const','sbp','tobacco','ldl','adiposity','famhist','obesity','alcohol','age']]  ## Predictors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE3NhzSJ3PSI",
        "outputId": "6386a312-574c-4811-b77e-c2f8f07fbf02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     row.names  sbp  tobacco    ldl  ...  alcohol  age  chd  const\n",
            "0            1  160    12.00   5.73  ...    97.20   52    1      1\n",
            "1            2  144     0.01   4.41  ...     2.06   63    1      1\n",
            "2            3  118     0.08   3.48  ...     3.81   46    0      1\n",
            "3            4  170     7.50   6.41  ...    24.26   58    1      1\n",
            "4            5  134    13.60   3.50  ...    57.34   49    1      1\n",
            "..         ...  ...      ...    ...  ...      ...  ...  ...    ...\n",
            "457        459  214     0.40   5.98  ...     0.00   58    0      1\n",
            "458        460  182     4.20   4.41  ...    18.72   52    1      1\n",
            "459        461  108     3.00   1.59  ...    26.64   55    0      1\n",
            "460        462  118     5.40  11.61  ...    23.97   40    0      1\n",
            "461        463  132     0.00   4.82  ...     0.00   46    1      1\n",
            "\n",
            "[462 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = dfx.to_numpy()   \n",
        "X_train = sm.add_constant(X_train)\n",
        "y_train = dfy.to_numpy()  \n",
        "X_test  = dfxt.to_numpy()   \n",
        "X_test = sm.add_constant(X_train)\n",
        "y_test  = dfyt.to_numpy()   \n",
        "#X_train.tofile('sample.csv',sep=',')"
      ],
      "metadata": {
        "id": "BVyOCV1VixLw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, obtenemos un modelo de predicción de los datos de entrenamiento usando regresión logística de la librería **statsmodels**. Como podemos ver algunas de las variables resultan ser no significativas con un valor P menor que 0.05. Tal es el caso de *alcohol, obesity, adiposity* y *sbp*. "
      ],
      "metadata": {
        "id": "m7ifENmLcu4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = sm.Logit(dfy, dfx)\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xhj6XmIM_8Wq",
        "outputId": "e90d72c3-f40f-47c7-9d2f-89772bd04ac3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.522778\n",
            "         Iterations 6\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                    chd   No. Observations:                  462\n",
            "Model:                          Logit   Df Residuals:                      453\n",
            "Method:                           MLE   Df Model:                            8\n",
            "Date:                Sat, 29 Jan 2022   Pseudo R-squ.:                  0.1897\n",
            "Time:                        06:23:01   Log-Likelihood:                -241.52\n",
            "converged:                       True   LL-Null:                       -298.05\n",
            "Covariance Type:            nonrobust   LLR p-value:                 8.931e-21\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -3.9658      1.068     -3.715      0.000      -6.058      -1.873\n",
            "sbp            0.0056      0.006      0.996      0.319      -0.005       0.017\n",
            "tobacco        0.0795      0.026      3.033      0.002       0.028       0.131\n",
            "ldl            0.1803      0.059      3.072      0.002       0.065       0.295\n",
            "adiposity      0.0101      0.028      0.357      0.721      -0.046       0.066\n",
            "famhist        0.9407      0.225      4.181      0.000       0.500       1.382\n",
            "obesity       -0.0457      0.043     -1.067      0.286      -0.130       0.038\n",
            "alcohol        0.0005      0.004      0.118      0.906      -0.008       0.009\n",
            "age            0.0404      0.012      3.437      0.001       0.017       0.063\n",
            "==============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De acuerdo con el libro, se aplicó una técnica de reducción de variables paso a paso **(Stepwise)** en el se encuentra un subconjunto de las variables que son suficientes para explicar el efecto conjunto de los predictores sobre la variable *chd*. El procedimiento descarta el coeficiente P menos significativo `pmenor` y el modelo se reajusta. Esto se hace repetidamente hasta que no se puedan eliminar más variables del modelo.\n",
        "Los resultados obtenidos en la tabla coinciden con los del libro.\n"
      ],
      "metadata": {
        "id": "_8jPgHMXD8tS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se ordenan los valores p y se selecciona el más pequeño\n",
        "p_values = results.pvalues.sort_values(ascending = False)\n",
        "pmenor = p_values.head(1)\n",
        "\n",
        "print(\"menorpi.item() \", pmenor.item())\n",
        "\n",
        "while pmenor.item() > 0.01:\n",
        "    print(pmenor.index.tolist())\n",
        "    dfx = dfx.drop(pmenor.index.tolist(), axis=1)\n",
        "    model = sm.Logit(dfy, dfx)\n",
        "    model = model.fit()\n",
        "    # Se ordenan los valores p y se selecciona el más pequeño\n",
        "    p_values = model.pvalues.sort_values(ascending = False)\n",
        "    pmenor = p_values.head(1)\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn0rQURKD8Ok",
        "outputId": "c9e72444-217b-4c75-d7f6-99fce77cd00f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "menorpi.item()  0.9062256410652616\n",
            "['alcohol']\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.522793\n",
            "         Iterations 6\n",
            "['adiposity']\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.522936\n",
            "         Iterations 6\n",
            "['sbp']\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.524131\n",
            "         Iterations 6\n",
            "['obesity']\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.525372\n",
            "         Iterations 6\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                    chd   No. Observations:                  462\n",
            "Model:                          Logit   Df Residuals:                      457\n",
            "Method:                           MLE   Df Model:                            4\n",
            "Date:                Sat, 29 Jan 2022   Pseudo R-squ.:                  0.1856\n",
            "Time:                        06:23:02   Log-Likelihood:                -242.72\n",
            "converged:                       True   LL-Null:                       -298.05\n",
            "Covariance Type:            nonrobust   LLR p-value:                 5.251e-23\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -4.2043      0.498     -8.436      0.000      -5.181      -3.228\n",
            "tobacco        0.0807      0.026      3.163      0.002       0.031       0.131\n",
            "ldl            0.1676      0.054      3.093      0.002       0.061       0.274\n",
            "famhist        0.9241      0.223      4.141      0.000       0.487       1.362\n",
            "age            0.0440      0.010      4.520      0.000       0.025       0.063\n",
            "==============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, evaluamos el desempeño del modelo calculando la exactitud y la matriz de confusión."
      ],
      "metadata": {
        "id": "7FK3R082ju6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat       = model.predict(dfx)\n",
        "prediction = list(map(round, yhat))\n",
        "\n",
        "# Calculamos la matriz de confusión\n",
        "cm = confusion_matrix(dfy, prediction)\n",
        "print (\"Confusion Matrix : \\n\", cm)\n",
        " \n",
        "# Exactitud del modelo\n",
        "print('Test accuracy = ', accuracy_score(dfy, prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcYRj8Y6donW",
        "outputId": "e4e3964c-c642-4731-dc2d-e30c31bf935d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix : \n",
            " [[254  48]\n",
            " [ 76  84]]\n",
            "Test accuracy =  0.7316017316017316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def confussion(cm):\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.imshow(cm)\n",
        "    ax.grid(False)\n",
        "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
        "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
        "    ax.set_ylim(1.5, -0.5)\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
        "    plt.show()\n",
        "confussion(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "WwHlGHFnpBLH",
        "outputId": "5cbf8d63-0965-49a7-c9b3-1cba7db1da25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAHSCAYAAAAe1umcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWVElEQVR4nO3cebSkdX3n8c+3FxqbhmZVbGjAM4qggmwKwQ0Ux4W4kOhJMI6aYUTNREaT6JhxjEaTM6MQnRhzjGAcB5fBFeMKBpdBEBdQASWyJAiyyNLsiNDLb/64BV6xobtvg7f7y+t1Tp+ueqqep763oOpdz1PP7RpjBADoYc5sDwAA3HeEHQAaEXYAaETYAaARYQeARoQdABqZN9sD/KZtu/XcscvS+bM9BrR1wTkLZ3sEaO/mXH/tGGO71d32gAv7Lkvn5zsnL53tMaCtZyzZa7ZHgPZOGZ+85J5ucygeABoRdgBoRNgBoBFhB4BGhB0AGhF2AGhE2AGgEWEHgEaEHQAaEXYAaETYAaARYQeARoQdABoRdgBoRNgBoBFhB4BGhB0AGhF2AGhE2AGgEWEHgEaEHQAaEXYAaETYAaARYQeARoQdABoRdgBoRNgBoBFhB4BGhB0AGhF2AGhE2AGgEWEHgEaEHQAaEXYAaETYAaARYQeARoQdABoRdgBoRNgBoBFhB4BGhB0AGhF2AGhE2AGgEWEHgEaEHQAaEXYAaETYAaARYQeARoQdABoRdgBoRNgBoBFhB4BGhB0AGhF2AGhE2AGgEWEHgEaEHQAaEXYAaETYAaARYQeARoQdABoRdgBoRNgBoBFhB4BGhB0AGhF2AGhE2AGgEWEHgEaEHQAaEXYAaETYAaARYQeARoQdABoRdgBoRNgBoBFhB4BGhB0AGhF2AGhE2AGgEWEHgEaEHQAaEXYAaETYAaARYQeARoQdABoRdgBoRNgBoBFhB4BGhB0AGhF2AGhE2AGgEWEHgEaEHQAaEXYAaETYAaARYQeARoQdABoRdgBoRNgBoBFhB4BGhB0AGhF2AGhk3mwPwAPc5ctTR12dXLMiqcp48RbJy7dMHbMs+chNyTZzkyTjz7dJnrbZL9e7bHnqKZdm/NnWyau2mqXhYeM1Z4z8fb6Sa7Np3lRPzN7jqrw852ZORm7LvBydx+WKWjTbYzIDa7XHXlXPr6pRVbutxX1fU1ULZzpQVb2sqt6zmuVVVe+uqouq6pyq2memj8EGZF5lvHmbjFN3zvjCjqkP3picf0eSZBy5ZcYpO2WcstOvRj1JveXa5Kkz/t8MHvAOy4W5NJvfdf2ofD//M4/PK+vp+Wp2yh/kX2ZxOtbH2h6KPzzJaZO/1+Q1Se6Pd9xnJXnE5M+RSd57PzwGv2kPmZfsuenU5UVzkkdskvxsxb2v86Vbkp3mJ4/c5P6fDxradvw8++fKfCkPu2vZSLIwy5Mkm2V5lmXTWZqO9bXGsFfVoiRPTHJEkt+ftnxuVR1TVT+c7EG/uqqOSrIkydeq6muT+90ybZ0XVNUHJ5efU1XfrqrvV9UpVfWQNYzyvCTHjynfSrJlVT108ufUqvrBZJYnreNzwIbip8uTc29P9pl6Q6kP3Jh66qWp116V3LBy6j63rkr9/fUZf7r1LA4KG7dX5ewclz2zatqyd2bf/HVOz0fHF3JILskJWeMBWjZQa7PH/rwkJ40xLkiyrKr2nSw/MskuSfYaY+yZ5CNjjHcnuSLJwWOMg9ew3dOSHDDG2DvJCUlev4b775Dkp9OuXzZZ9qIkJ48x9kry2CQ/WIufiQ3NratSR/ws463bJpvPyXjp4oxv7ZxxytLkwfNSf3ltkqSOuS7jyC2TzZz3CTOx/7giN2RBLqxfPTfld3Nh3pgn5EV1aE7OLnllzp6lCVlfa3Py3OFJ/nZy+YTJ9bOSHJLkH8YYK5JkjHHdOj72jkk+VlUPTbJJkovXcf07fTfJB6pqfpLPjDF+LexVdWSmPohkpx2cL7jBWT5SR1yZ8TuLkkMnJ+ts98v/TuPFW6T+w5VTV773i9Tnb0netiy5aVVqTjIWVPIft5yFwWHj8+gsy2/lyjx+fDGbZGUWZkX+apyWpbk5P65tkiRfz9L8j3xjlidlpu61clW1dZKnJtmjqkaSuUlGVb1uHR5jTLs8/Uubv0vyzjHGZ6vqoCRvWcN2Lk+ydNr1HZNcPsa4sqqenOTQJB+sqneOMY7/lQHGODbJsUmy32M3nT4Ps22M1J9cPfXd+iun7UFctWLq+/ck+eKtyW5T36ePf9rxrrvUMcsyNpsj6rAOPlB75APZI0my57g6L8wFeXMOzMfz+ewwbs7ltXn2zVW5NFvM8qTM1Jp2X1+Q5ENjjFfcuaCq/l+SJyX55ySvqKqvjTFWVNXWk732m5NsnuTaySpXVdXuSc5Pctjk9iRZnKlYJ8lL12LWzyb546o6Icn+SW6cRH3nJJeNMY6rqgVJ9kly/L1tiA3Id36R+uTNGbtvkjrk0iRTv9pWJ96S/Oj2pJIsnZfxjgfP7pzQ2Kqak3eNffPmnJFVo3JL5ueY7DfbYzFDawr74Unefrdln5osf3WSXZOcU1XLkxyX5D2Z2jM+qaqumHzP/oYkn09yTZIzk9z5i5FvSfKJqro+yVeTaadnrt4Xkzw7yUVJfp7kDyfLD0ryuskMtyR5yRq2w4Zk/wdl1ZUP/7XF426/3rY648+2uT8mggeMc+rBOSdTH5pPrx1yenaY5Ym4L9QYD6wj0/s9dtPxnZOXrvmOwIw8Y8lesz0CtHfK+ORZY4zVHlZxajEANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Aj82Z7gN+0Cy/cOs965u/P9hjQ1jhwwWyPAP2d/sl7vMkeOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPzZnsAmG7HXyzLf7vk03dd3/6O6/Oh7Z+SE7fbP8+95rt57rIzsyqVb2/xiPzjkqfN4qSw8frdy7+ZZ111ZkZVLl74kBz9iMOyfM78JMl//rcv5JlXfS/P+a03zfKUzNRahb2qnp/kxCS7jzF+vIb7vibJsWOMn89koKp6WZL9xhh/fLfluyX530n2SfLGMcYxM9k+G7bLNt0mf/TIlydJ5oxV+ch5f5vTFz8yj73lJznwpvPzql1fnuVz5mXx8ltneVLYOG1z+015/pVn5Ii9j8odc+fnTT8+IQdfc26+/JB9suvNl2fRittme0TW09oeij88yWmTv9fkNUkWzniie3ZdkqOSCPoDxF63XJwrN9kqV2+yZX772rPysQcfmOVzpj6L3jh/s1meDjZec8eqLFi1PHPGyixYtTzLNtkic8aqHPmTk3PcLs+Y7fFYT2vcY6+qRUmemOTgJJ9L8ubJ8rlJ3p7kmUlWJTkuSSVZkuRrVXXtGOPgqrpljLFoss4Lkvz2GONlVfWcJP89ySZJliX5gzHGVfc0xxjj6iRXV9Whd5tvsyQfT7JjkrlJ3jbG+Ng6PAdsoA66/rx8fatHJ0l2uP26PObWn+ZlP/t67qh5OW7JIblg4ZJZnhA2PssWbJFP7PDEfPTMv8ntc+blrC0fnrO2engOu+KMnLH1brluk81ne0TW09rssT8vyUljjAuSLKuqfSfLj0yyS5K9xhh7JvnIGOPdSa5IcvAY4+A1bPe0JAeMMfZOckKS18/kB8jUB4srxhiPHWM8JslJM9wOG5B5q1bmgJsuyKmLd0+SzM2qbL7itvyXh/9h3r/kaXnjJZ9KxpjlKWHjs2jFbTnwun/Ji/f7k/ze416fTVfdkadf/f085dof5sQl+8/2eNwH1ibsh2cqvJn8fefh+EOSvG+MsSJJxhjXreNj75jk5Ko6N8nrkjx6Hde/07lJnl5Vb6+qJ40xbrz7HarqyKo6s6rOvGOF72Y3Bo+7+aJc9KDtc8P8RUmSa+dvntO33C2pyvkLd8iqVBavnNFpHPCAts8N/5qfLdgqN87fLCvnzM1p2zwqL7n0q1nyi+ty/Fn/Kx8+82+yYNXy/J+z3jXbozJD93oovqq2TvLUJHtU1cjUoe5RVa9bh8eYvlu16bTLf5fknWOMz1bVQUnesg7b/OXGx7igqvZJ8uwkf1VVXxljvPVu9zk2ybFJsnjhErt5G4GDbvjRXYfhk+SbW0ydQHf2ol2yw+3LMn+szI1z749TOaC3qxcszu43/zQLVt6R2+fMz943/Fs+teQJ+cySA+66z+fOeFteuu9rZ3FK1sea9thfkORDY4ydxxi7jDGWJrk4yZOS/HOSV1TVvOSuDwFJcnOS6V/SXFVVu1fVnCSHTVu+OMnlk8svnekPUFVLkvx8jPHhJEdn6qx5NmILVt6RfW6+OKct3u2uZSdvvVe2v/2GvO/89+XPLzkxRy99blI1i1PCxunHmy/Nqds+Ou89+7057gfvSWXkC9vvN9tjcR9a08lzh2fqBLnpPjVZ/uokuyY5p6qWZ+rkufdkas/4pKq6YvI9+xuSfD7JNUnOTLJosp23JPlEVV2f5KtJHnZvg1TV9pP1t0iyavJrdY9KskeSo6tqVZLlSV61hp+JDdztczfJCx/zp7+ybMWcuXnHzs+fpYmgl+N3elqO3+me/x0Iv8O+cavxADsBafHCJeOAXY+Y7TGgrZWLFsz2CNDeV05/01ljjNUeavFPygJAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQiLADQCPCDgCNCDsANCLsANCIsANAI8IOAI0IOwA0IuwA0IiwA0Ajwg4AjQg7ADQi7ADQSI0xZnuG36iquibJJbM9B+tk2yTXzvYQ0JzX2cZl5zHGdqu74QEXdjY+VXXmGGO/2Z4DOvM668OheABoRNgBoBFhZ2Nw7GwPAA8AXmdN+I4dABqxxw4AjQg7a62qVlbVD6rqh1X1iapauB7b+mBVvWBy+f1V9ah7ue9BVXXgDB7jJ1W17WqW71tV51bVRVX17qqqdd023F8avc7+uqp+WlW3rOs2WT/Czrq4bYyx1xjjMUnuSPLK6TdW1byZbHSM8Z/GGOfdy10OSrLObzj34r1JXp7kEZM/z7wPtw3rq8vr7HNJHn8fbo+1JOzM1DeSPHzyKf8bVfXZJOdV1dyqOrqqvltV51TVK5Kkprynqs6vqlOSPPjODVXV16tqv8nlZ1bV96rq7Kr6SlXtkqk3ttdO9mKeVFXbVdWnJo/x3ap6wmTdbarqy1X1o6p6f5Jf2xOvqocm2WKM8a0xdYLJ8UmeP7ntqKo6bzL3Cffjcwdra6N8nSXJ5DV25d2XV9ULJ0cjzq6qU+/bp4skmdEnPx7YJnsMz0py0mTRPkkeM8a4uKqOTHLjGONxVbUgyelV9eUkeyd5ZJJHJXlIkvOSfOBu290uyXFJnjzZ1tZjjOuq6h+S3DLGOGZyv48medcY47Sq2inJyUl2T/LmJKeNMd5aVYcmOWI14++Q5LJp1y+bLEuSNyR52Bjj9qracj2eIlhvG/nr7N78RZJnjDEu9zq7fwg76+JBVfWDyeVvJPnHTB26+84Y4+LJ8n+fZM87v9dLsjhTh7ufnOT/jjFWJrmiqr66mu0fkOTUO7c1xrjuHuY4JMmjpn01vkVVLZo8xu9M1v1CVV2/jj/fOUk+UlWfSfKZdVwX7ivdX2enJ/lgVX08yafXcV3WgrCzLm4bY+w1fcHkRX/r9EVJXj3GOPlu93v2fTjHnCQHjDF+sZpZ1uTyJDtOu77jZFmSHJqpN63nJHljVe0xxlix/uPCOunwOrtHY4xXVtX+mXq9nVVV+44xlq3XRvkVvmPnvnZykldV1fwkqapdq2qzJKcm+b3Jd4MPTXLwatb9VpInV9XDJutuPVl+c5LNp93vy0lefeeVqrrzTfDUJC+aLHtWkq3u/gCT7/xuqqoDauod6iVJ/qmq5iRZOsb4WpL/mqk9oEUzeQLgN2CDfp3dm6r6d2OMb48x/iLJNUmWrsv6rJmwc197f6a+1/teVf0wyfsydWToxCQXTm47PskZd19xjHFNkiOTfLqqzk7ysclNn0ty2J0n9SQ5Ksl+k5OGzssvzxr+y0y9Yf0oU4cKL72HGf9oMudFSf41yZeSzE3y4ao6N8n3k7x7jHHDzJ8GuF9t8K+zqnpHVV2WZGFVXVZVb5ncdHRN/brpD5N8M8nZ6/NE8Ov8y3MA0Ig9dgBoRNgBoBFhB4BGhB0AGhF2AGhE2AGgEWEHgEaEHQAa+f9pwNUiFHUKUgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra manera de calcular una regresión logistica es con la librería **sklearn** tal como se muestra a continuación."
      ],
      "metadata": {
        "id": "lVNgnL1wB2D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logisticRegr = LogisticRegression()\n",
        "logisticRegr.fit(X_train, y_train)\n",
        "logisticRegr.predict(X_test[0].reshape(1,-1))\n",
        "logisticRegr.predict(X_test[0:10])\n",
        "predictions = logisticRegr.predict(X_test)\n",
        "error = y_test - predictions\n",
        "# Use score method to get accuracy of model\n",
        "score = logisticRegr.score(X_test, y_test)\n",
        "parametros=logisticRegr.get_params(deep=False)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aZF0sMP226n",
        "outputId": "4c4dc932-5842-428a-eb95-9bee5a11223f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7229437229437229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rgresión logística aplicada a clasificación de regiones de consumo de electricidad.\n",
        "\n"
      ],
      "metadata": {
        "id": "FOj3Dk6DbT3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#https://www-datasklr-com.translate.goog/select-classification-methods/linear-and-quadratic-discriminant-analysis?_x_tr_sl=en&_x_tr_tl=es&_x_tr_hl=en-US&_x_tr_pto=wapp"
      ],
      "metadata": {
        "id": "57jD89iuoo_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "D94BAPhUsUke"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Procesamos datos de entrenamiento \n",
        "df = pd.read_csv('r_Regiones_100s_train.csv')\n",
        "df=df.assign(const=1)\n",
        "dfy = df['Clase'] \n",
        "dfx = df[['GenTer','GenHid','GenRE','GenNP','GenTot','Demanda','PotInt','Perdidas','PrecioMarginal']]  ## Predictors\n",
        "X = dfx.to_numpy() \n",
        "#X = sm.add_constant(X) para agregar una constante en uno\n",
        "y = dfy.to_numpy()"
      ],
      "metadata": {
        "id": "GIiDMhxBgdxj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Crea conjuntos de datos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 5)"
      ],
      "metadata": {
        "id": "oh4y5otKsXHp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LDA_model_default = LinearDiscriminantAnalysis()\n",
        "LDA_model_default.fit(X_test, y_test)\n",
        "y_pred_LDA_default =LDA_model_default.predict(X_test)\n",
        "print(y_pred_LDA_default)\n",
        "y_pred_LDA_default.tofile('sample.csv',sep=',')\n",
        "y_test.tofile('y.csv',sep=',')\n",
        "score = logisticRegr.score(X_test, y_test)\n",
        "parametros = logisticRegr.get_params(deep=False)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKHhUkB5y9Dw",
        "outputId": "e5474f32-16bd-406d-b004-7a9fb2f397ac"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16 67  2 ... 51 13 12]\n",
            "0.0168681219556197\n"
          ]
        }
      ]
    }
  ]
}