{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJdmZlRiHs/WnzTqT9thLE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urieliram/statistical/blob/main/Tarea8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import warnings\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV, LarsCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import scipy.stats\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import bernoulli\n",
        "import statsmodels.tools.eval_measures as bias\n",
        "import seaborn as sns\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from scipy.stats import bernoulli\n",
        "from scipy.stats import norm"
      ],
      "metadata": {
        "id": "9i3WmNoTReGd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leemos los datos para un ejemplo de una variable"
      ],
      "metadata": {
        "id": "DOwecwXEGS9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('logreg1.csv')\n",
        "df = df.assign(const=1)\n",
        "print(df)\n",
        "dfy = df['frac'].to_numpy() \n",
        "dfx = df[['const','sex','age']].to_numpy()  ## Predictors\n",
        "x   = pd.DataFrame(df[['age']]).to_numpy()\n",
        "#Y   = pd.DataFrame(df[['Y']]).to_numpy()\n",
        "n = dfx.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDwX24SfRGax",
        "outputId": "aeab552a-56b2-465e-89ac-0c760240b3ab"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    sex  age  frac  const\n",
            "0     1   69     1      1\n",
            "1     1   57     1      1\n",
            "2     1   61     1      1\n",
            "3     0   60     0      1\n",
            "4     1   69     1      1\n",
            "..  ...  ...   ...    ...\n",
            "95    1   68     0      1\n",
            "96    1   75     1      1\n",
            "97    1   52     0      1\n",
            "98    1   53     0      1\n",
            "99    1   70     1      1\n",
            "\n",
            "[100 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l7wPXsCgTBN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = np.zeros(n); frac = np.zeros(n); Likelihood = 1\n",
        "\n",
        "alpha=0; b_sex=1; b_age=1; #inicial data\n",
        "for i in range(n):\n",
        "\n",
        "    ## Linear regression on logit\n",
        "    #model = sm.Logit(dfy, dfx)\n",
        "    #p[i] = alpha + b_sex * dfx[i,1] + b_age * dfx[i,2] #<----------cambiar a logit\n",
        "    ## Likelihood function for each data point\n",
        "    #print(p[i])\n",
        "    #frac[i]  = bernoulli(0.01, p)\n",
        "\n",
        "    exp_e = np.exp(alpha + b_sex * dfx[i,1] + b_age * dfx[i,2])\n",
        "    \n",
        "    Likelihood = Likelihood * np.power(exp_e/(1+exp_e),dfy[i]) * np.power(1-exp_e/(1+exp_e),1-dfy[i])\n",
        "\n",
        "\n",
        "alpha = norm(0.0,1.0E-2) # Prior for intercept\n",
        "b_sex = norm.ppf([0.001, 0.5, 0.999])\n",
        "b_age = norm.ppf([0.001, 0.5, 0.999])"
      ],
      "metadata": {
        "id": "u-ryj--daYUk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, comparamos los resultados con un análisis frecuentista de regresión logística de la librería **statsmodels**."
      ],
      "metadata": {
        "id": "DtBCIUz4StoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = sm.Logit(dfy, dfx)\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u57E-JTJSETl",
        "outputId": "15709930-a370-46c1-bc39-129959edd691"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.297593\n",
            "         Iterations 8\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   No. Observations:                  100\n",
            "Model:                          Logit   Df Residuals:                       97\n",
            "Method:                           MLE   Df Model:                            2\n",
            "Date:                Sun, 20 Feb 2022   Pseudo R-squ.:                  0.5484\n",
            "Time:                        15:29:35   Log-Likelihood:                -29.759\n",
            "converged:                       True   LL-Null:                       -65.896\n",
            "Covariance Type:            nonrobust   LLR p-value:                 2.024e-16\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const        -21.8504      4.425     -4.938      0.000     -30.524     -13.177\n",
            "x1             1.3611      0.733      1.856      0.063      -0.076       2.798\n",
            "x2             0.3447      0.069      5.027      0.000       0.210       0.479\n",
            "==============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "queremos saber las distribuciones de probabilidad de los parámetros desconocidos del modelo.\n",
        "\n",
        "Probar que tan buenos son unos parámetros. Cuanto mayor sea la probabilidad P(teta|x) de los valores de los parámetros dados los datos, más probable será que sean los parámetros \"reales\" de la distribución de la población.\n",
        "\n",
        "Esto significa que podemos transformar nuestro problema de encontrar los parámetros de la distribución de la población, a encontrar los valores de los parámetros que maximizan el valor P(θ|x).\n",
        "\n",
        "podemos transformar nuestro problema de encontrar los parámetros de la distribución de la población, a encontrar los valores de los parámetros que maximizan el valor P(θ|x)."
      ],
      "metadata": {
        "id": "lJawpsZXJwKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Bayesian Learning for Machine Learning: Part II - Linear Regression](https://wso2.com/blog/research/part-two-linear-regression/)\n",
        "\n",
        "[Logistic regression with PyMC3](https://goldinlocks.github.io/Bayesian-logistic-regression-with-pymc3/)\n",
        "\n",
        "[An Introduction to Logistic Regression in Python\n",
        "](https://www.simplilearn.com/tutorials/machine-learning-tutorial/logistic-regression-in-python)\n",
        "\n",
        "[Bayesian inference tutorial: a hello world example](https://datapythonista.me/blog/bayesian-inference-tutorial-a-hello-world-example.html)\n",
        "\n",
        "[Ejemplo de Bayes con covid y síntomas](https://statsthinking21.github.io/statsthinking21-python/10-BayesianStatistics.html)\n",
        "\n",
        "[Estimating Probabilities with Bayesian Modeling in Python](https://towardsdatascience.com/estimating-probabilities-with-bayesian-modeling-in-python-7144be007815)\n",
        "\n",
        "[Estimando probabilidades con inferencia bayesiana](https://github.com/WillKoehrsen/probabilistic-programming/blob/master/Estimating%20Probabilities%20with%20Bayesian%20Inference.ipynb)\n",
        "\n",
        "Bayesian Linear Regression in Python: Using Machine Learning to Predict Student Grades: [Parte 1](https://towardsdatascience.com/bayesian-linear-regression-in-python-using-machine-learning-to-predict-student-grades-part-1-7d0ad817fca5) y [Parte2](https://towardsdatascience.com/bayesian-linear-regression-in-python-using-machine-learning-to-predict-student-grades-part-2-b72059a8ac7e)\n",
        "\n",
        "[Bayesian Inference in Python](https://towardsai.net/p/l/bayesian-inference-in-python) \n",
        "\n",
        "[Bayesian Statistics explained to Beginners in Simple English](Bayesian Statistics explained to Beginners in Simple English)\n",
        "\n",
        "[Bayesian inference in Python-coursera](https://www.coursera.org/lecture/advanced-machine-learning-signal-processing/bayesian-inference-in-python-9D2Pz)\n",
        "\n",
        "[A Guide to Bayesian Statistics in Python for Beginners](https://analyticsindiamag.com/a-guide-to-bayesian-statistics-in-python-for-beginners/)\n",
        "\n",
        "[BBN: Bayesian Belief Networks — How to Build Them Effectively in Python](https://towardsdatascience.com/bbn-bayesian-belief-networks-how-to-build-them-effectively-in-python-6b7f93435bba)\n",
        "\n",
        "[Saúl Dobilas](https://solclover.com/)\n",
        "\n"
      ],
      "metadata": {
        "id": "6GLSZRSRlDIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pymc3 as pm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from theano import shared, tensor as tt\n",
        "\n",
        "def invlogit(x):\n",
        "    \"\"\"\n",
        "    sigmoid operator\n",
        "    :param x: int/float or array like data-structure\n",
        "    :return: sigmoid of x\n",
        "    \"\"\"\n",
        "    if type(x) is np.ndarray:\n",
        "        return np.exp(x) / (1 + np.exp(x))\n",
        "    return tt.exp(x) / (1 + tt.exp(x))\n",
        "\n",
        "\n",
        "size = 100  # no of data samples\n",
        "true_intercept = 0.5  # intercept of the regression line\n",
        "true_slope = 2  # slop (coefficient) of x\n",
        "\n",
        "#x = np.linspace(0, 1, size)  # generate some random values for x in the given range (0,1)\n",
        "\n",
        "# performs simple linear regression\n",
        "# y = sigmoid(a + b*x)\n",
        "true_regression_line = invlogit(true_intercept + true_slope * x)\n",
        "\n",
        "# we can't use true regression values for training the model\n",
        "# therefore, add some random noise\n",
        "y = true_regression_line + np.random.normal(scale=.3, size=size)\n",
        "\n",
        "# assume this is a binary classifications\n",
        "# convert y values to labels\n",
        "true_regression_line = true_regression_line >= 0.5\n",
        "y = y >= 0.5\n",
        "\n",
        "# split the data points into train and test split\n",
        "x_train, x_test, y_train, y_test, true_y1, true_y2 = train_test_split(x, y, true_regression_line)\n",
        "\n",
        "# we use a shared variable from theano to feed the x values into the model\n",
        "# this is need for PPC\n",
        "# when using the model for predictions we can set this shared variable to x_test\n",
        "shared_x = shared(x_train)\n",
        "\n",
        "# training the model\n",
        "# model specifications in PyMC3 are wrapped in a with-statement\n",
        "with pm.Model() as model:\n",
        "    # Define priors\n",
        "    x_coeff = pm.Normal('x', 0, sd=20)  # prior for coefficient of x\n",
        "    intercept = pm.Normal('Intercept', 0, sd=20)  # prior for the intercept\n",
        "    sigma = pm.HalfCauchy('sigma', beta=10)  # prior for the error term of due to the noise\n",
        "\n",
        "    reg = intercept + tt.dot(shared_x, x_coeff)\n",
        "    p = pm.Deterministic(\"p\", invlogit(reg))  # represent the logistic regression relationship\n",
        "\n",
        "    # Define likelihood\n",
        "    likelihood = pm.Bernoulli('y', p=p, observed=y_train)\n",
        "\n",
        "    # Inference!\n",
        "    trace = pm.sample(1000)  # draw 3000 posterior samples using NUTS sampling\n",
        "\n",
        "# predicting the unseen y values\n",
        "# uses posterior predictive checks (PPC)\n",
        "shared_x.set_value(x_test)  # let's set the shared x to the test dataset\n",
        "ppc = pm.sample_ppc(trace, model=model, samples=1000)  # performs PPC\n",
        "predictions = ppc['y'].mean(axis=0)  # compute the mean of the samples draws from each new y\n",
        "\n",
        "predictions = predictions >= 0.5\n",
        "# now you can check the error\n",
        "print(\"Accuracy of logistic regression using bayesian : {0}\".format(accuracy_score(y_test, predictions)))\n",
        "\n",
        "# plot the traceplot\n",
        "pm.traceplot(trace)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "-lg-FyPBZNa-",
        "outputId": "3b6bcda6-1a86-436d-9cb8-33bc65647e54"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-28fc20e45835>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Define likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mlikelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# Inference!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymc3/distributions/distribution.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getnewargs__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymc3/model.py\u001b[0m in \u001b[0;36mVar\u001b[0;34m(self, name, dist, data, total_size, dims)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                     \u001b[0mdistribution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mtotal_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 )\n\u001b[1;32m   1184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserved_RVs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymc3/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, type, owner, index, name, data, distribution, total_size, model)\u001b[0m\n\u001b[1;32m   1826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogp_elemwiset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m             \u001b[0;31m# The logp might need scaling in minibatches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m             \u001b[0;31m# This is done in `Factor`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymc3/distributions/discrete.py\u001b[0m in \u001b[0;36mlogp\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             return bound(\n\u001b[0;32m--> 453\u001b[0;31m                 \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m             )\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/theano/graph/op.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_test_value\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"off\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0mcompute_test_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/theano/graph/op.py\u001b[0m in \u001b[0;36mcompute_test_value\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mthunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mrequired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrequired\u001b[0m  \u001b[0;31m# We provided all inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/theano/graph/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m()\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/theano/link/c/basic.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1769\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input dimension mis-match. (input[0].shape[1] = 100, input[1].shape[1] = 1)"
          ]
        }
      ]
    }
  ]
}