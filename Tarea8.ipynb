{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOunkIuUd0LW/0WFr4HCae1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urieliram/statistical/blob/main/Tarea8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import warnings\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV, LarsCV\n",
        "from sklearn.metrics import (roc_curve, roc_auc_score, confusion_matrix, accuracy_score, f1_score, precision_recall_curve) \n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy.stats import bernoulli\n",
        "from scipy.stats import norm\n",
        "import scipy.stats\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.tools.eval_measures as bias\n",
        "import seaborn as sns\n",
        "import arviz as az\n",
        "import pymc3 as pm\n",
        "import theano.tensor as tt\n",
        "from IPython.core.pylabtools import figsize\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(\"Running on PyMC3 v{pm.__version__}\")"
      ],
      "metadata": {
        "id": "9i3WmNoTReGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee1c939-8913-4043-ff63-c4389770a9d9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on PyMC3 v{pm.__version__}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inferencia Bayesiana\n",
        "queremos saber las distribuciones de probabilidad de los parámetros desconocidos del modelo.\n",
        "\n",
        "Probar que tan buenos son unos parámetros. Cuanto mayor sea la probabilidad P(teta|x) de los valores de los parámetros dados los datos, más probable será que sean los parámetros \"reales\" de la distribución de la población.\n",
        "\n",
        "Esto significa que podemos transformar nuestro problema de encontrar los parámetros de la distribución de la población, a encontrar los valores de los parámetros que maximizan el valor P(θ|x).\n",
        "\n",
        "podemos transformar nuestro problema de encontrar los parámetros de la distribución de la población, a encontrar los valores de los parámetros que maximizan el valor P(θ|x)."
      ],
      "metadata": {
        "id": "lJawpsZXJwKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leemos los datos para un ejemplo de dos variables"
      ],
      "metadata": {
        "id": "DOwecwXEGS9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('bones.csv')\n",
        "df = df.assign(const=1)\n",
        "#print(df)\n",
        "dfy = df['frac'] \n",
        "dfx = df[['const','sex','age']] ## Predictors\n",
        "x   = pd.DataFrame(df[['sex','age']]).to_numpy()\n",
        "y   = pd.DataFrame(df[['frac']]).to_numpy()\n",
        "df.sample(5)\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "SDwX24SfRGax",
        "outputId": "58252deb-0b46-43e3-b386-7bd129a73e48"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e71a1498-f493-4459-ab87-6f86cfcf48bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>frac</th>\n",
              "      <th>const</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100.00</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.55</td>\n",
              "      <td>64.980000</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.50</td>\n",
              "      <td>8.671304</td>\n",
              "      <td>0.485237</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.00</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.00</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.00</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.00</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e71a1498-f493-4459-ab87-6f86cfcf48bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e71a1498-f493-4459-ab87-6f86cfcf48bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e71a1498-f493-4459-ab87-6f86cfcf48bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          sex         age        frac  const\n",
              "count  100.00  100.000000  100.000000  100.0\n",
              "mean     0.55   64.980000    0.630000    1.0\n",
              "std      0.50    8.671304    0.485237    0.0\n",
              "min      0.00   50.000000    0.000000    1.0\n",
              "25%      0.00   57.000000    0.000000    1.0\n",
              "50%      1.00   66.000000    1.000000    1.0\n",
              "75%      1.00   72.000000    1.000000    1.0\n",
              "max      1.00   80.000000    1.000000    1.0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Un ejemplo básico de regresión logistica bayesiana\n",
        "El ejemplo usado es un modelo de regresión logística simulado de fracturas óseas con variables independientes de edad y sexo. Fuente: [Lawrence Joseph](http://www.medicine.mcgill.ca/epidemiology/Joseph/courses/EPIB-621/main.html) [PDF](http://www.medicine.mcgill.ca/epidemiology/joseph/courses/EPIB-621/bayeslogit.pdf)"
      ],
      "metadata": {
        "id": "Xit5CqMALj2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al principio no sabemos nada sobre los parámetros `beta` así que usaremos una distribución **uniforme**  con límites suficientemente grandes como los valores: `lower = -10**6; higher = 10**6 `\n"
      ],
      "metadata": {
        "id": "is-o6Mlkmcd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lower = -10**6; higher = 10**6\n",
        "with pm.Model() as first_model:\n",
        "    ## Priors on parameters\n",
        "    beta_0   = pm.Uniform('beta_0', lower=lower, upper= higher)\n",
        "    beta_sex = pm.Uniform('beta_sex', lower, higher)\n",
        "    beta_age = pm.Uniform('beta_age', lower, higher)\n",
        "    \n",
        "    #the probability of output equal to 1\n",
        "    p = pm.Deterministic('p', pm.math.sigmoid(beta_0+beta_sex*df['sex']+ beta_age*df['age']))\n",
        "\n",
        "with first_model:\n",
        "    #fit the data \n",
        "    observed=pm.Bernoulli(\"frac\", p, observed=df['frac'])\n",
        "    start = pm.find_MAP()\n",
        "    step  = pm.Metropolis()\n",
        "    \n",
        "    #samples from posterior distribution \n",
        "    trace=pm.sample(25000, step=step, start=start)\n",
        "    first_burned_trace=trace[15000:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "D_IPVGHrbRCX",
        "outputId": "3b855ed8-0044-4b4e-8096-e89b503f4a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='44' class='' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [44/44 00:00<00:00 logp = -73.285, ||grad|| = 4.0855e+05]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sequential sampling (2 chains in 1 job)\n",
            "CompoundStep\n",
            ">Metropolis: [beta_age]\n",
            ">Metropolis: [beta_sex]\n",
            ">Metropolis: [beta_0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='15170' class='' max='26000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      58.35% [15170/26000 00:21<00:15 Sampling chain 0, 0 divergences]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Graficamos las distribuciones resultantes de nuestro primer modelo\n",
        "pm.traceplot(first_burned_trace, figsize=[14,14])\n",
        "plt.savefig('fig_t8_1.png', transparent=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DQht9Vugb7fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Ahora calculamos la media de nuestra primera versión de las muestras generadas por la simulación.\n",
        "coeffs=['beta_0', 'beta_sex', 'beta_age']\n",
        "d=dict()\n",
        "for item in coeffs:\n",
        "    d[item]=[first_burned_trace[item].mean()]\n",
        "    \n",
        "result_coeffs=pd.DataFrame.from_dict(d)    \n",
        "result_coeffs\n",
        "#coeff_result=pd.DataFrame(d)    \n",
        "#coeff_result"
      ],
      "metadata": {
        "id": "dgYDFwv2cdeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una ventaja del enfoque de inferencia bayesiana es que no solo nos da la media de los parámtros del modelo, también podemos obtener los intervalos de confianza al 95%. Es decir que los Los parámetros buscados se encontrarán entre los valores siguientes con una probabilidad del 95%. "
      ],
      "metadata": {
        "id": "S7zMVqsPqt9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = first_burned_trace['beta_0'].mean()\n",
        "hpd = az.hdi(first_burned_trace['beta_0'].flatten())\n",
        "\n",
        "coeffs=['beta_0', 'beta_sex', 'beta_age']\n",
        "interval=dict()\n",
        "for item in coeffs:\n",
        "    interval[item]=az.hdi(first_burned_trace[item].flatten()) #compute 95% high density interval\n",
        "    \n",
        "result_coeffs=pd.DataFrame.from_dict(interval).rename(index={0: 'lower', 1: 'upper'})\n",
        "result_coeffs"
      ],
      "metadata": {
        "id": "VnyDyAKhn7zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los valores buscados se encuentran entre estos valores, ahora podemos refinar la búsqueda de los parámetros usando estos límites en un segundo modelo."
      ],
      "metadata": {
        "id": "3CUhri4LabQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with pm.Model() as second_model:\n",
        "    ## Priors on parameters\n",
        "    beta_0   = pm.Uniform('beta_0',   lower=-31.561240, upper= -20.376186)\n",
        "    beta_sex = pm.Uniform('beta_sex', lower=0.555843,   upper=2.816436)\n",
        "    beta_age = pm.Uniform('beta_age', lower=0.314423,   upper=0.487489)\n",
        "    \n",
        "    #the probability of output equal to 1\n",
        "    p = pm.Deterministic('p', pm.math.sigmoid(beta_0+beta_sex*df['sex']+ beta_age*df['age']))\n",
        "    \n",
        "with second_model:\n",
        "    #fit the data \n",
        "    observed=pm.Bernoulli(\"frac\", p, observed=df['frac'])\n",
        "    start = pm.find_MAP()\n",
        "    step = pm.Metropolis()\n",
        "    \n",
        "    #samples from posterior distribution \n",
        "    trace=pm.sample(25000, step=step, start=start)\n",
        "    second_burned_trace=trace[15000:]"
      ],
      "metadata": {
        "id": "kT45ZwNJr4wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Graficamos las distribuciones resultantes de nuestro segundo modelo\n",
        "pm.traceplot(second_burned_trace, figsize=[14,14])\n",
        "plt.savefig('fig_t8_2.png', transparent=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tgr6mVsnt2xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Ahora calculamos la media de nuestra primera versión de las muestras generadas por la simulación.\n",
        "coeffs=['beta_0', 'beta_sex', 'beta_age']\n",
        "d=dict()\n",
        "for item in coeffs:\n",
        "    d[item]=[second_burned_trace[item].mean()]\n",
        "    \n",
        "result_coeffs=pd.DataFrame.from_dict(d)    \n",
        "print(result_coeffs)"
      ],
      "metadata": {
        "id": "z3YO77SAuExl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Ahora calculamos intervalos al 95%.\n",
        "mean = second_burned_trace['beta_0'].mean()\n",
        "hpd = az.hdi(second_burned_trace['beta_0'].flatten())\n",
        "\n",
        "coeffs=['beta_0', 'beta_sex', 'beta_age']\n",
        "interval=dict()\n",
        "for item in coeffs:\n",
        "    interval[item]=az.hdi(second_burned_trace[item].flatten()) #compute 95% high density interval\n",
        "    \n",
        "result_coeffs=pd.DataFrame.from_dict(interval).rename(index={0: 'lower', 1: 'upper'})\n",
        "print(result_coeffs)"
      ],
      "metadata": {
        "id": "-7dqgkqKuExm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, entrenemos el modelo asumiendo que los coeficientes de la regresión logistica siguen distribuciones normales. Es decir cambiaremos el conjunto de priors en un tercer modelo."
      ],
      "metadata": {
        "id": "dFDUsmK2uzx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with pm.Model() as third_model:  \n",
        "    ## Priors on parameters\n",
        "    beta_0   = pm.Normal('beta_0'  , mu=-23.764747, sd=10**4)\n",
        "    beta_sex = pm.Normal('beta_sex', mu=1.572192, sd=10**4)\n",
        "    beta_age = pm.Normal('beta_age', mu=0.37384, sd=10**4)\n",
        "    \n",
        "    #the probability of output equal to 1\n",
        "    p = pm.Deterministic('p', pm.math.sigmoid(beta_0+beta_sex*df['sex']+ beta_age*df['age']))\n",
        "    \n",
        "with third_model:\n",
        "    #fit the data \n",
        "    observed=pm.Bernoulli(\"frac\", p, observed=df['frac'])\n",
        "    start = pm.find_MAP()\n",
        "    step = pm.Metropolis()\n",
        "    \n",
        "    #samples from posterior distribution \n",
        "    trace=pm.sample(25000, step=step, start=start)\n",
        "    third_burned_trace=trace[15000:]"
      ],
      "metadata": {
        "id": "HaJOkUQZuwg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Graficamos las distribuciones resultantes de nuestro tercer modelo\n",
        "pm.traceplot(third_burned_trace, figsize=[14,14])\n",
        "plt.savefig('fig_t8_3.png', transparent=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0XXeUfawvtH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Ahora calculamos la media de nuestra primera versión de las muestras generadas por la simulación.\n",
        "coeffs=['beta_0', 'beta_sex', 'beta_age']\n",
        "d=dict()\n",
        "for item in coeffs:\n",
        "    d[item]=[third_burned_trace[item].mean()]\n",
        "    \n",
        "result_coeffs=pd.DataFrame.from_dict(d)    \n",
        "print(result_coeffs)"
      ],
      "metadata": {
        "id": "oIskIQXfvtH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Ahora calculamos intervalos al 95%.\n",
        "mean = third_burned_trace['beta_0'].mean()\n",
        "hpd = az.hdi(third_burned_trace['beta_0'].flatten())\n",
        "\n",
        "coeffs=['beta_0', 'beta_sex', 'beta_age']\n",
        "interval=dict()\n",
        "for item in coeffs:\n",
        "    interval[item]=az.hdi(third_burned_trace[item].flatten()) #compute 95% high density interval\n",
        "    \n",
        "result_coeffs=pd.DataFrame.from_dict(interval).rename(index={0: 'lower', 1: 'upper'})\n",
        "print(result_coeffs)"
      ],
      "metadata": {
        "id": "rSc5L5SJvtH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos ver los intervalos son mas cerrados a los que teníamos en el primer modelo."
      ],
      "metadata": {
        "id": "Gvt_aMFWwR35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo lineal generalizado (GLM) en PyMC3 en fracturas oseas.\n",
        "Hemos hecho un análisis inferencial bayesiano expresando los priors de cada una de las variables. Sin embargo, cuando el número de variables es muy grande, **PyMC3** tiene un modelo lineal generalizado en el que todo esta automatizado. Se usará este modelo para ajustar nuestros datos."
      ],
      "metadata": {
        "id": "zy2CZkMq9SFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with pm.Model() as fourth_model:\n",
        "    pm.glm.GLM.from_formula('frac ~ sex + age',df, \n",
        "                            family=pm.glm.families.Binomial())\n",
        "    fourth_trace = pm.sample(25000, tune=10000, init='adapt_diag')\n",
        "pm.traceplot(fourth_trace, figsize=[12,14])\n",
        "plt.savefig('fig_t8_4.png', transparent=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dQDotsiX5Kha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pm.summary(fourth_trace)"
      ],
      "metadata": {
        "id": "MU2Rrw0hDi3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with fourth_model:\n",
        "    map_solution=pm.find_MAP()\n",
        "d=dict()\n",
        "for item in map_solution.keys():\n",
        "    d[item]=[float(map_solution[item])]\n",
        "    \n",
        "fourth_map_coeffs=pd.DataFrame.from_dict(d)    \n",
        "fourth_map_coeffs"
      ],
      "metadata": {
        "id": "g9nglWKSBVPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Ahora calculamos la media de nuestra primera versión de las muestras generadas por la simulación.\n",
        "coeffs=['age', 'sex', 'Intercept']\n",
        "d=dict()\n",
        "for item in coeffs:\n",
        "    d[item]=[fourth_trace[item].mean()]\n",
        "    \n",
        "result_coeffs=pd.DataFrame.from_dict(d)    \n",
        "print(result_coeffs)"
      ],
      "metadata": {
        "id": "Tz0Fumkz8b5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Ahora calculamos intervalos al 95%.\n",
        "mean = fourth_trace['Intercept'].mean()\n",
        "hpd = az.hdi(fourth_trace['Intercept'].flatten())\n",
        "\n",
        "coeffs=['age', 'sex', 'Intercept']\n",
        "interval=dict()\n",
        "for item in coeffs:\n",
        "    interval[item]=az.hdi(fourth_trace[item].flatten()) #compute 95% high density interval\n",
        "    \n",
        "result_coeffs=pd.DataFrame.from_dict(interval).rename(index={0: 'lower', 1: 'upper'})\n",
        "print(result_coeffs)"
      ],
      "metadata": {
        "id": "biwS2mhP8b5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último, calculamos la matriz de confusión del ajuste al modelo de regresión logistica"
      ],
      "metadata": {
        "id": "5KPVjR0bEI2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with fourth_model:\n",
        "    ppc = pm.sample_posterior_predictive(fourth_trace, samples=15000)\n",
        "#compute y_score \n",
        "with fourth_model:\n",
        "    fourth_y_score = np.mean(ppc['y'], axis=0)\n",
        "#convert y_score into binary decisions    \n",
        "fourth_model_prediction=[1 if x >0.5 else 0 for x in fourth_y_score]\n",
        "#compute confussion matrix \n",
        "fourth_model_confussion_matrix = confusion_matrix(df['frac'], fourth_model_prediction)\n",
        "fourth_model_confussion_matrix"
      ],
      "metadata": {
        "id": "yIZbFuq12NLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Versión frecuentista de la regresión logística con la librería *statsmodel*."
      ],
      "metadata": {
        "id": "eifx_Ki8cGuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, comparamos los resultados con un análisis frecuentista de regresión logística de la librería **statsmodels**."
      ],
      "metadata": {
        "id": "DtBCIUz4StoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = sm.Logit(dfy, dfx)\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "metadata": {
        "id": "u57E-JTJSETl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predicción de sobrecarga en grupos de líneas de transmisión.\n",
        "En esta sección se usará inferencia bayesiana para ajustar un modelo de regresión logística a datos de violación de flujo de potencia eléctrica en grupos de líneas de transmisión, que interconectan regiones eléctricas. La variable dependientes es de naturaleza binaria con un valor de uno si la línea presenta sobrecarga y cero si no. Las variables independientes son el flujo neto máximo y mínimo en la región eléctrica en un día y se calcula como la diferencia entre la demanda menos la generación en cada región.\n"
      ],
      "metadata": {
        "id": "z59rI5XjFzoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('overload.csv')\n",
        "df = df.assign(const=1)\n",
        "print(df)\n",
        "dfy = df['L3'] #Se escoge le número de línea de transmisión\n",
        "dfx = df[['CEN','NES','NOR','NTE','OCC','ORI','PEN','CEN_min','NES_min','NOR_min','NTE_min','OCC_min','ORI_min','PEN_min']] ## Predictors\n",
        "df.sample(5)\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "YHm2TKzKJj1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with pm.Model() as fourth_model:\n",
        "    pm.glm.GLM.from_formula('L3 ~ CEN +  NES + NOR + NTE + OCC + ORI +  PEN + CEN_min + NES_min + NOR_min + NTE_min + OCC_min + ORI_min + PEN_min',df, \n",
        "                            family=pm.glm.families.Binomial())\n",
        "    fourth_trace = pm.sample(25000, tune=10000, init='adapt_diag')\n",
        "#https://pymc3-testing.readthedocs.io/en/rtd-docs/api/plots.html\n",
        "#https://python.hotexamples.com/examples/pymc3/-/traceplot/python-traceplot-function-examples.html\n",
        "\n",
        "pm.traceplot(fourth_trace, figsize=[16,70]) \n",
        "plt.savefig('fig_t8_5.png', transparent=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V8u_XvG4Kbdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pm.summary(fourth_trace)"
      ],
      "metadata": {
        "id": "LEbpb1UfKbdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with fourth_model:\n",
        "    map_solution=pm.find_MAP()\n",
        "d=dict()\n",
        "for item in map_solution.keys():\n",
        "    d[item]=[float(map_solution[item])]\n",
        "    \n",
        "fourth_map_coeffs=pd.DataFrame.from_dict(d)    \n",
        "fourth_map_coeffs"
      ],
      "metadata": {
        "id": "j08kmckYKbdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Ahora calculamos la media de de las muestras generadas por la simulación.\n",
        "coeffs=['CEN','NES','NOR','NTE','OCC','ORI','PEN','CEN_min','NES_min','NOR_min','NTE_min','OCC_min','ORI_min','PEN_min','Intercept']\n",
        "d=dict()\n",
        "for item in coeffs:\n",
        "    d[item]=[fourth_trace[item].mean()]\n",
        "    \n",
        "result_coeffs=pd.DataFrame.from_dict(d)    \n",
        "print(result_coeffs)"
      ],
      "metadata": {
        "id": "wIk30C6lKbdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Ahora calculamos intervalos al 95%.\n",
        "mean = fourth_trace['Intercept'].mean()\n",
        "hpd = az.hdi(fourth_trace['Intercept'].flatten())\n",
        "\n",
        "coeffs=['CEN','NES','NOR','NTE','OCC','ORI','PEN','CEN_min','NES_min','NOR_min','NTE_min','OCC_min','ORI_min','PEN_min','Intercept']\n",
        "interval=dict()\n",
        "for item in coeffs:\n",
        "    interval[item]=az.hdi(fourth_trace[item].flatten()) #compute 95% high density interval\n",
        "    \n",
        "result_coeffs=pd.DataFrame.from_dict(interval).rename(index={0: 'lower', 1: 'upper'})\n",
        "print(result_coeffs)"
      ],
      "metadata": {
        "id": "9ZyjWjVFKbdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último, calculamos la matriz de confusión del ajuste al modelo de regresión logistica"
      ],
      "metadata": {
        "id": "e-fV10CIKbdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with fourth_model:\n",
        "    ppc = pm.sample_posterior_predictive(fourth_trace, samples=15000)\n",
        "#compute y_score \n",
        "with fourth_model:\n",
        "    fourth_y_score = np.mean(ppc['y'], axis=0)\n",
        "#convert y_score into binary decisions    \n",
        "fourth_model_prediction=[1 if x >0.5 else 0 for x in fourth_y_score]\n",
        "#compute confussion matrix \n",
        "fourth_model_confussion_matrix = confusion_matrix(df['L3'], fourth_model_prediction)\n",
        "fourth_model_confussion_matrix"
      ],
      "metadata": {
        "id": "F7L4s2h9Kbdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Versión frecuentista de la regresión logística con la librería *statsmodel*."
      ],
      "metadata": {
        "id": "Fr3c1hjTe4fB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, comparamos los resultados con un análisis frecuentista de regresión logística de la librería **statsmodels**."
      ],
      "metadata": {
        "id": "49cfpfXhe4fC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = sm.Logit(dfy, dfx)\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "metadata": {
        "id": "5rxywt6ue4fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conclusión:** \n",
        "Hemos utilizado **PyMC3** para implementar la regresión logistica bayesiana para varias variables, además de la función **Logit** de la librería *statsmodel*, que implementa un enfoque frecuentista.\n",
        "Los resultados de estimación de parámetros entre el enfoque frecuentista y el bayesiano son muy parecidos, sin embargo, el enfoque bayesiano da algunas ventajas ya que da la posibilidad de actualizar el modelo con nueva información, mientras que los modelos de regresión lineal generan valores únicos de los parámetros de ajuste, mientras que los modelos de regresión lineal bayesianos pueden generar distribuciones de los parámetros.\n",
        "Esto tiene la ventaja de que podemos cuantificar la incertidumbre de nuestra estimación.\n",
        "Otra cosa que observamos es que a pesar de que los modelos modelos bayesianos que usamos usan distribuciones prior diferentes, los rendimientos de predicción son similares. Esto quiere decir que a medida que crece el conjunto de datos los resultados deberían converger en la misma solución."
      ],
      "metadata": {
        "id": "pzCSYQf80z2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Bayesian logistic regression with PyMC3](https://towardsdatascience.com/bayesian-logistic-regression-with-pymc3-8e17c576f31a)\n",
        "\n",
        "[Bayesian Linear Regression in Python via PyMC3](https://towardsdatascience.com/bayesian-linear-regression-in-python-via-pymc3-ab8c2c498211)\n",
        "\n",
        "[PyMC3](https://docs.pymc.io/en/v3/nb_examples/index.html)\n",
        "\n",
        "[Logistic regression with PyMC3](https://goldinlocks.github.io/Bayesian-logistic-regression-with-pymc3/)\n",
        "\n",
        "[Bayesian statistics by Lawrence Joseph (Medicine)](http://www.medicine.mcgill.ca/epidemiology/Joseph/courses/EPIB-621/main.html) [PDF](http://www.medicine.mcgill.ca/epidemiology/joseph/courses/EPIB-621/bayeslogit.pdf)\n",
        "\n",
        "[Bayesian Learning for Machine Learning: Part II - Linear Regression](https://wso2.com/blog/research/part-two-linear-regression/)\n",
        "\n",
        "[An Introduction to Logistic Regression in Python](https://www.simplilearn.com/tutorials/machine-learning-tutorial/logistic-regression-in-python)\n",
        "\n",
        "[Bayesian inference tutorial: a hello world example](https://datapythonista.me/blog/bayesian-inference-tutorial-a-hello-world-example.html)\n",
        "\n",
        "[Ejemplo de Bayes con covid y síntomas](https://statsthinking21.github.io/statsthinking21-python/10-BayesianStatistics.html)\n",
        "\n",
        "[Estimating Probabilities with Bayesian Modeling in Python](https://towardsdatascience.com/estimating-probabilities-with-bayesian-modeling-in-python-7144be007815)\n",
        "\n",
        "[Estimando probabilidades con inferencia bayesiana](https://github.com/WillKoehrsen/probabilistic-programming/blob/master/Estimating%20Probabilities%20with%20Bayesian%20Inference.ipynb)\n",
        "\n",
        "Bayesian Linear Regression in Python: Using Machine Learning to Predict Student Grades: [Parte 1](https://towardsdatascience.com/bayesian-linear-regression-in-python-using-machine-learning-to-predict-student-grades-part-1-7d0ad817fca5) y [Parte2](https://towardsdatascience.com/bayesian-linear-regression-in-python-using-machine-learning-to-predict-student-grades-part-2-b72059a8ac7e)\n",
        "\n",
        "[Bayesian Inference in Python](https://towardsai.net/p/l/bayesian-inference-in-python) \n",
        "\n",
        "[Bayesian Statistics explained to Beginners in Simple English](Bayesian Statistics explained to Beginners in Simple English)\n",
        "\n",
        "[Bayesian inference in Python-coursera](https://www.coursera.org/lecture/advanced-machine-learning-signal-processing/bayesian-inference-in-python-9D2Pz)\n",
        "\n",
        "[A Guide to Bayesian Statistics in Python for Beginners](https://analyticsindiamag.com/a-guide-to-bayesian-statistics-in-python-for-beginners/)\n",
        "\n",
        "[BBN: Bayesian Belief Networks — How to Build Them Effectively in Python](https://towardsdatascience.com/bbn-bayesian-belief-networks-how-to-build-them-effectively-in-python-6b7f93435bba)\n",
        "\n",
        "[Bayesian multivariate linear regression Yni](https://en.wikipedia.org/wiki/Bayesian_multivariate_linear_regression#:~:text=In%20statistics%2C%20Bayesian%20multivariate%20linear,a%20single%20scalar%20random%20variable.)\n",
        "\n"
      ],
      "metadata": {
        "id": "6GLSZRSRlDIr"
      }
    }
  ]
}